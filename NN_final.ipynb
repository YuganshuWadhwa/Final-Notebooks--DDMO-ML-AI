{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CLASSIFICATION USING NEURAL NETWORK <br>WITH HYPERPARAMETER TUNING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "## Deep learning models\n",
    "\n",
    "Deep learning is a method in **artificial intelligence** (AI) that enables computers to process data in a manner inspired by the human brain. By using neural networks with **multiple layers**, deep learning models have the ability to recognize and understand complex patterns in various types of data, including images, text, sounds, and more. This enables deep learning models to provide accurate insights and make predictions based on the learned patterns. \n",
    "\n",
    "<br>\n",
    "\n",
    "![alt text](https://datafloq.com/wp-content/uploads/2021/12/blog_pictures2FDeep_Learning_2360-750x420.png \"AI\")\n",
    "\n",
    "<sup><sub>Source: [wdatafloq.com](https://datafloq.com/read/deep-learning-methods-machine-learning/)</sub></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## Neural network\n",
    "\n",
    "Neural network uses **interconnected nodes or neurons** in a layered structure that resembles the human brain. Each neuron **takes inputs, applies weights** to them, performs a mathematical operation, and passes the result to the next layer. Through a process called training, neural networks adjust the weights to learn patterns in the data to make accurate predictions or classifications based on the provided data. Among common application areas are image and speech recognition as well as prediction models. \n",
    "\n",
    "<br>\n",
    "\n",
    "![alt text](https://i0.wp.com/i.postimg.cc/pLgLsJDt/Architecture.jpg?w=1230&ssl=1 \"NN Structure\")\n",
    "\n",
    "<sup><sub>Source: [blog.knoldus.com](https://i0.wp.com/i.postimg.cc/pLgLsJDt/Architecture.jpg?w=1230&ssl=1)</sub></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## Important components of a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Input Layer**\n",
    "\n",
    "The input layer is the first layer of the neural network which receives the input data. Each node in the input layer represents a feature or an element of the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### **Output Layer**\n",
    "\n",
    "The output layer is the final layer of the neural network which provides the predictions or outputs of the network based on the computations and transformations performed in the preceding layers. In multi-class classification, the output layer may have multiple nodes, where each node represents the probability or prediction of each individual class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### **Neurons** or **Nodes**\n",
    "\n",
    "Neurons are the basic units of computation in a neural network. Each neuron (organized into layers) receives inputs, performs computations using weights and biases, and produces an output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### **Weights** and **Biases**\n",
    "\n",
    "Each connection between the neurons has a weight associated with it, which determines the strength or importance of that connection. Biases provide an additional constant term that helps control the activation of neurons. These learn-able parameters are important during training of the network to minimize the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### **Activation Function**\n",
    "\n",
    "A neural network without an activation function is essentially just a linear regression model. The activation function perfomrs the non-linear transformation to the input making it capable to learn and perform more complex tasks. The activation function decides whether a neuron should be activated or not by calculating the weighted sum and further adding bias to it.\n",
    "\n",
    "Some common activation functions are: **Softmax**, **Sigmoid**, **Tanh** and **ReLU**\n",
    "\n",
    "<br>\n",
    "\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:1200/1*hkYlTODpjJgo32DoCOWN5w.png \"Neuron\")\n",
    "\n",
    "<sup><sub>Source: [medium.com](https://towardsdatascience.com/the-concept-of-artificial-neurons-perceptrons-in-neural-networks-fab22249cbfc)</sub></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### **Hidden Layers**\n",
    "\n",
    "Hidden layers in a neural network are the layers that exist between the input layer and the output layer. They are responsible for performing computations and transformations to learn representations and extract features from the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### **Loss Function**\n",
    "\n",
    "During neural network training, the loss function quantifies the error between predicted and true values, providing feedback for the model's learning. Backpropagation and the loss function work together to train the network by updating weights based on the calculated gradients and minimizing the discrepancy between predicted and true values. \n",
    "\n",
    "Some commonly used loss functions are: **Mean Squared Error (MSE) Loss** and **Cross-Entropy Loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### **Back Propagation**\n",
    "\n",
    "Backpropagation is a fundamental algorithm in the training of neural networks. It allows the neural network to learn from the data and adapt its weights to optimize performance for a given task. \n",
    "\n",
    "By iteratively performing the forward pass, backward pass, and weight updation steps on a training dataset, the network gradually learns to adjust its weights in a way that reduces the error and improves its ability to make accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### **Optimizer**\n",
    "\n",
    "Optimizers play a crucial role in training neural networks as they determine how the model learns and converges to the optimal solution. They adjust the parameters based on the computed gradients of the loss function with respect to the network's parameters. \n",
    "\n",
    "Some common optimizers are: **Stochastic Gradient Descent (SGD)**, **Adam (Adaptive Moment Estimation)** and **RMSProp (Root Mean Square Propagation)**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "![alt text](./images/backprop.png \"Back Propagation\")\n",
    "\n",
    "<sup><sub>Source: [Lecture Notes](https://git-ce.rwth-aachen.de/spotseven-lab/ml-ai-ait-sommersemester-2023/-/blob/main/LectureNotes.d/bart23b-ml-ai-01-public.ipynb)</sub></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## Different types of Neural Network structures\n",
    "\n",
    "* **Feedforward Neural Networks**: In this neural network the information flows from input layer through the hidden layers to the output layer. They are used for tasks such as classification and regression. \n",
    "\n",
    "* **Convolutional Neural Networks**: They use convolutional layers to extract spatial features from the input images, allowing them to capture patterns and structures effectively. CNNs are designed specifically for image processing tasks. \n",
    "\n",
    "* **Recurrent Neural Networks**: RNNs are designed to handle sequential data, such as time series or natural language. They have a feedback loop that allows them to have memory and consider context from previous inputs when making predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing Libraries and Device Agnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from spotPython.utils.metrics import mapk_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Setting `seed` values to increase reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Using `gpu` for tensor based mathematics\n",
    "\n",
    "* using `device` to force tensor operations, model allocation, and other computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## 1. Loading Dataset: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector Borne Disease Prediction Data\n",
    "\n",
    "The **Vector Borne Disease Dataset** was used in a study to predict medical prognosis. It consisted of hundreds of samples with case-specific features. The dataset included a target variable `prognosis` representing prognostic outcomes divided into **eleven classes**. To prepare the dataset for training a classifier model, preprocessing steps involved encoding prognosis names and performing feature engineering. **The goal was to predict the prognosis for unknown data based on the trained model.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>breathing_restriction</th>\n",
       "      <th>toe_inflammation</th>\n",
       "      <th>finger_inflammation</th>\n",
       "      <th>lips_irritation</th>\n",
       "      <th>itchiness</th>\n",
       "      <th>ulcers</th>\n",
       "      <th>toenail_loss</th>\n",
       "      <th>speech_problem</th>\n",
       "      <th>bullseye_rash</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lyme_disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tungiasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lyme_disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rift_Valley_fever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Plague</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Malaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Plague</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tungiasis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain   \n",
       "0             1.0       1.0          0.0         1.0          1.0         1.0  \\\n",
       "1             0.0       0.0          0.0         0.0          0.0         0.0   \n",
       "2             0.0       1.0          1.0         1.0          0.0         1.0   \n",
       "3             0.0       0.0          1.0         1.0          1.0         1.0   \n",
       "4             0.0       0.0          0.0         0.0          0.0         0.0   \n",
       "..            ...       ...          ...         ...          ...         ...   \n",
       "702           0.0       0.0          1.0         1.0          1.0         0.0   \n",
       "703           1.0       0.0          1.0         1.0          1.0         1.0   \n",
       "704           1.0       0.0          1.0         0.0          1.0         0.0   \n",
       "705           1.0       1.0          0.0         0.0          1.0         0.0   \n",
       "706           1.0       1.0          0.0         0.0          0.0         0.0   \n",
       "\n",
       "     vomiting  rash  diarrhea  hypotension  ...  breathing_restriction   \n",
       "0         1.0   0.0       1.0          1.0  ...                    0.0  \\\n",
       "1         1.0   0.0       1.0          0.0  ...                    0.0   \n",
       "2         1.0   1.0       1.0          1.0  ...                    1.0   \n",
       "3         0.0   1.0       0.0          1.0  ...                    0.0   \n",
       "4         0.0   0.0       1.0          0.0  ...                    0.0   \n",
       "..        ...   ...       ...          ...  ...                    ...   \n",
       "702       0.0   0.0       0.0          0.0  ...                    0.0   \n",
       "703       0.0   1.0       1.0          0.0  ...                    0.0   \n",
       "704       0.0   1.0       1.0          1.0  ...                    0.0   \n",
       "705       1.0   0.0       1.0          0.0  ...                    1.0   \n",
       "706       1.0   0.0       0.0          0.0  ...                    0.0   \n",
       "\n",
       "     toe_inflammation  finger_inflammation  lips_irritation  itchiness   \n",
       "0                 0.0                  0.0              0.0        0.0  \\\n",
       "1                 0.0                  0.0              0.0        0.0   \n",
       "2                 1.0                  1.0              1.0        1.0   \n",
       "3                 0.0                  0.0              0.0        0.0   \n",
       "4                 1.0                  0.0              0.0        1.0   \n",
       "..                ...                  ...              ...        ...   \n",
       "702               0.0                  0.0              0.0        0.0   \n",
       "703               0.0                  0.0              0.0        0.0   \n",
       "704               0.0                  0.0              0.0        0.0   \n",
       "705               1.0                  1.0              1.0        0.0   \n",
       "706               0.0                  0.0              0.0        1.0   \n",
       "\n",
       "     ulcers  toenail_loss  speech_problem  bullseye_rash          prognosis  \n",
       "0       0.0           0.0             0.0            0.0       Lyme_disease  \n",
       "1       0.0           0.0             0.0            0.0          Tungiasis  \n",
       "2       0.0           1.0             1.0            1.0       Lyme_disease  \n",
       "3       0.0           0.0             0.0            0.0               Zika  \n",
       "4       1.0           1.0             0.0            0.0  Rift_Valley_fever  \n",
       "..      ...           ...             ...            ...                ...  \n",
       "702     0.0           0.0             0.0            0.0             Plague  \n",
       "703     0.0           0.0             0.0            0.0            Malaria  \n",
       "704     0.0           0.0             0.0            0.0               Zika  \n",
       "705     0.0           0.0             0.0            0.0             Plague  \n",
       "706     1.0           1.0             0.0            0.0          Tungiasis  \n",
       "\n",
       "[707 rows x 65 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/Kaggle/train.csv')\n",
    "\n",
    "# remove the id column\n",
    "train_df = train_df.drop(columns=['id'])\n",
    "\n",
    "global target_column\n",
    "target_column = \"prognosis\"\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## 3. Splitting the Holdout Train and Test Data for Hyperparameter Tuning\n",
    "<br>\n",
    "\n",
    "![Division of Data](./images/data_division_nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "## 2. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### `Encoding`\n",
    "\n",
    "Encoding is a way of transforming categorical variables into a numerical format since the algorithm cannot work with categorical variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>breathing_restriction</th>\n",
       "      <th>toe_inflammation</th>\n",
       "      <th>finger_inflammation</th>\n",
       "      <th>lips_irritation</th>\n",
       "      <th>itchiness</th>\n",
       "      <th>ulcers</th>\n",
       "      <th>toenail_loss</th>\n",
       "      <th>speech_problem</th>\n",
       "      <th>bullseye_rash</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain   \n",
       "0             1.0       1.0          0.0         1.0          1.0         1.0  \\\n",
       "1             0.0       0.0          0.0         0.0          0.0         0.0   \n",
       "2             0.0       1.0          1.0         1.0          0.0         1.0   \n",
       "3             0.0       0.0          1.0         1.0          1.0         1.0   \n",
       "4             0.0       0.0          0.0         0.0          0.0         0.0   \n",
       "..            ...       ...          ...         ...          ...         ...   \n",
       "702           0.0       0.0          1.0         1.0          1.0         0.0   \n",
       "703           1.0       0.0          1.0         1.0          1.0         1.0   \n",
       "704           1.0       0.0          1.0         0.0          1.0         0.0   \n",
       "705           1.0       1.0          0.0         0.0          1.0         0.0   \n",
       "706           1.0       1.0          0.0         0.0          0.0         0.0   \n",
       "\n",
       "     vomiting  rash  diarrhea  hypotension  ...  breathing_restriction   \n",
       "0         1.0   0.0       1.0          1.0  ...                    0.0  \\\n",
       "1         1.0   0.0       1.0          0.0  ...                    0.0   \n",
       "2         1.0   1.0       1.0          1.0  ...                    1.0   \n",
       "3         0.0   1.0       0.0          1.0  ...                    0.0   \n",
       "4         0.0   0.0       1.0          0.0  ...                    0.0   \n",
       "..        ...   ...       ...          ...  ...                    ...   \n",
       "702       0.0   0.0       0.0          0.0  ...                    0.0   \n",
       "703       0.0   1.0       1.0          0.0  ...                    0.0   \n",
       "704       0.0   1.0       1.0          1.0  ...                    0.0   \n",
       "705       1.0   0.0       1.0          0.0  ...                    1.0   \n",
       "706       1.0   0.0       0.0          0.0  ...                    0.0   \n",
       "\n",
       "     toe_inflammation  finger_inflammation  lips_irritation  itchiness   \n",
       "0                 0.0                  0.0              0.0        0.0  \\\n",
       "1                 0.0                  0.0              0.0        0.0   \n",
       "2                 1.0                  1.0              1.0        1.0   \n",
       "3                 0.0                  0.0              0.0        0.0   \n",
       "4                 1.0                  0.0              0.0        1.0   \n",
       "..                ...                  ...              ...        ...   \n",
       "702               0.0                  0.0              0.0        0.0   \n",
       "703               0.0                  0.0              0.0        0.0   \n",
       "704               0.0                  0.0              0.0        0.0   \n",
       "705               1.0                  1.0              1.0        0.0   \n",
       "706               0.0                  0.0              0.0        1.0   \n",
       "\n",
       "     ulcers  toenail_loss  speech_problem  bullseye_rash  prognosis  \n",
       "0       0.0           0.0             0.0            0.0        3.0  \n",
       "1       0.0           0.0             0.0            0.0        7.0  \n",
       "2       0.0           1.0             1.0            1.0        3.0  \n",
       "3       0.0           0.0             0.0            0.0       10.0  \n",
       "4       1.0           1.0             0.0            0.0        6.0  \n",
       "..      ...           ...             ...            ...        ...  \n",
       "702     0.0           0.0             0.0            0.0        5.0  \n",
       "703     0.0           0.0             0.0            0.0        4.0  \n",
       "704     0.0           0.0             0.0            0.0       10.0  \n",
       "705     0.0           0.0             0.0            0.0        5.0  \n",
       "706     1.0           1.0             0.0            0.0        7.0  \n",
       "\n",
       "[707 rows x 65 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OrdinalEncoder()\n",
    "train_df[target_column] = enc.fit_transform(train_df[[target_column]])\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### `Feature Combination`\n",
    "\n",
    "This is performed to create new features by combining existing features in a dataset using some logic. This process aims to add additional information that may not be evident in the original features alone. In our case this is achieved by applying the boolean operators `and`, `or` and `xor` on the initial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(df):\n",
    "\n",
    "    for col1, col2 in itertools.combinations(df.columns,2):\n",
    "        df[f'{col1}_and_{col2}'] = df[col1] & df[col2]\n",
    "        df[f'{col1}_or_{col2}'] = df[col1] | df[col2]\n",
    "        df[f'{col1}_xor_{col2}'] = df[col1] ^ df[col2]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>toenail_loss_and_speech_problem</th>\n",
       "      <th>toenail_loss_or_speech_problem</th>\n",
       "      <th>toenail_loss_xor_speech_problem</th>\n",
       "      <th>toenail_loss_and_bullseye_rash</th>\n",
       "      <th>toenail_loss_or_bullseye_rash</th>\n",
       "      <th>toenail_loss_xor_bullseye_rash</th>\n",
       "      <th>speech_problem_and_bullseye_rash</th>\n",
       "      <th>speech_problem_or_bullseye_rash</th>\n",
       "      <th>speech_problem_xor_bullseye_rash</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 6113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain   \n",
       "0               1         1            0           1            1           1  \\\n",
       "1               0         0            0           0            0           0   \n",
       "2               0         1            1           1            0           1   \n",
       "3               0         0            1           1            1           1   \n",
       "4               0         0            0           0            0           0   \n",
       "..            ...       ...          ...         ...          ...         ...   \n",
       "702             0         0            1           1            1           0   \n",
       "703             1         0            1           1            1           1   \n",
       "704             1         0            1           0            1           0   \n",
       "705             1         1            0           0            1           0   \n",
       "706             1         1            0           0            0           0   \n",
       "\n",
       "     vomiting  rash  diarrhea  hypotension  ...   \n",
       "0           1     0         1            1  ...  \\\n",
       "1           1     0         1            0  ...   \n",
       "2           1     1         1            1  ...   \n",
       "3           0     1         0            1  ...   \n",
       "4           0     0         1            0  ...   \n",
       "..        ...   ...       ...          ...  ...   \n",
       "702         0     0         0            0  ...   \n",
       "703         0     1         1            0  ...   \n",
       "704         0     1         1            1  ...   \n",
       "705         1     0         1            0  ...   \n",
       "706         1     0         0            0  ...   \n",
       "\n",
       "     toenail_loss_and_speech_problem  toenail_loss_or_speech_problem   \n",
       "0                                  0                               0  \\\n",
       "1                                  0                               0   \n",
       "2                                  1                               1   \n",
       "3                                  0                               0   \n",
       "4                                  0                               1   \n",
       "..                               ...                             ...   \n",
       "702                                0                               0   \n",
       "703                                0                               0   \n",
       "704                                0                               0   \n",
       "705                                0                               0   \n",
       "706                                0                               1   \n",
       "\n",
       "     toenail_loss_xor_speech_problem  toenail_loss_and_bullseye_rash   \n",
       "0                                  0                               0  \\\n",
       "1                                  0                               0   \n",
       "2                                  0                               1   \n",
       "3                                  0                               0   \n",
       "4                                  1                               0   \n",
       "..                               ...                             ...   \n",
       "702                                0                               0   \n",
       "703                                0                               0   \n",
       "704                                0                               0   \n",
       "705                                0                               0   \n",
       "706                                1                               0   \n",
       "\n",
       "     toenail_loss_or_bullseye_rash  toenail_loss_xor_bullseye_rash   \n",
       "0                                0                               0  \\\n",
       "1                                0                               0   \n",
       "2                                1                               0   \n",
       "3                                0                               0   \n",
       "4                                1                               1   \n",
       "..                             ...                             ...   \n",
       "702                              0                               0   \n",
       "703                              0                               0   \n",
       "704                              0                               0   \n",
       "705                              0                               0   \n",
       "706                              1                               1   \n",
       "\n",
       "     speech_problem_and_bullseye_rash  speech_problem_or_bullseye_rash   \n",
       "0                                   0                                0  \\\n",
       "1                                   0                                0   \n",
       "2                                   1                                1   \n",
       "3                                   0                                0   \n",
       "4                                   0                                0   \n",
       "..                                ...                              ...   \n",
       "702                                 0                                0   \n",
       "703                                 0                                0   \n",
       "704                                 0                                0   \n",
       "705                                 0                                0   \n",
       "706                                 0                                0   \n",
       "\n",
       "     speech_problem_xor_bullseye_rash  prognosis  \n",
       "0                                   0          3  \n",
       "1                                   0          7  \n",
       "2                                   0          3  \n",
       "3                                   0         10  \n",
       "4                                   0          6  \n",
       "..                                ...        ...  \n",
       "702                                 0          5  \n",
       "703                                 0          4  \n",
       "704                                 0         10  \n",
       "705                                 0          5  \n",
       "706                                 0          7  \n",
       "\n",
       "[707 rows x 6113 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.astype(int)\n",
    "\n",
    "col_prognosis = train_df[target_column]\n",
    "train_x = train_df.drop(columns=['prognosis'])\n",
    "train_x = combine_features(train_x)\n",
    "train_x['prognosis'] = col_prognosis\n",
    "train_df = train_x.copy()\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### `Clustering`\n",
    "\n",
    "To gather more information from the data, ***feature clustering*** was applied. This involved summing up the number of features that contained a specific keyword (for example `pain`) in their name and had a value of 1 in a specific sample. The sum was then added to a new column (say, `c_0`). \n",
    "\n",
    "This combines and counts the occurrences of pain-related symptoms in the dataset, and represent the overall presence or intensity of the symptom pain for each sample in the data. \n",
    "\n",
    "The clustering process allows to simplify and condense multiple individual features into a single aggregated cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_features(df):    \n",
    "    c_0 = df.columns[df.columns.str.contains('pain')]\n",
    "    c_1 = df.columns[df.columns.str.contains('inflammation')]\n",
    "    c_2 = df.columns[df.columns.str.contains('bleed')]\n",
    "    c_3 = df.columns[df.columns.str.contains('skin')]\n",
    "    df[\"c_0\"] = df[c_0].sum(axis=1)\n",
    "    df[\"c_1\"] = df[c_1].sum(axis=1)\n",
    "    df[\"c_2\"] = df[c_2].sum(axis=1)\n",
    "    df[\"c_3\"] = df[c_3].sum(axis=1) \n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>toenail_loss_or_bullseye_rash</th>\n",
       "      <th>toenail_loss_xor_bullseye_rash</th>\n",
       "      <th>speech_problem_and_bullseye_rash</th>\n",
       "      <th>speech_problem_or_bullseye_rash</th>\n",
       "      <th>speech_problem_xor_bullseye_rash</th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>707</td>\n",
       "      <td>168</td>\n",
       "      <td>356</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>36</td>\n",
       "      <td>157</td>\n",
       "      <td>137</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>822</td>\n",
       "      <td>375</td>\n",
       "      <td>496</td>\n",
       "      <td>252</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>235</td>\n",
       "      <td>425</td>\n",
       "      <td>252</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>147</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511</td>\n",
       "      <td>203</td>\n",
       "      <td>409</td>\n",
       "      <td>165</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>199</td>\n",
       "      <td>320</td>\n",
       "      <td>163</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>174</td>\n",
       "      <td>295</td>\n",
       "      <td>183</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>759</td>\n",
       "      <td>330</td>\n",
       "      <td>367</td>\n",
       "      <td>252</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>66</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 6117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain   \n",
       "0               1         1            0           1            1           1  \\\n",
       "1               0         0            0           0            0           0   \n",
       "2               0         1            1           1            0           1   \n",
       "3               0         0            1           1            1           1   \n",
       "4               0         0            0           0            0           0   \n",
       "..            ...       ...          ...         ...          ...         ...   \n",
       "702             0         0            1           1            1           0   \n",
       "703             1         0            1           1            1           1   \n",
       "704             1         0            1           0            1           0   \n",
       "705             1         1            0           0            1           0   \n",
       "706             1         1            0           0            0           0   \n",
       "\n",
       "     vomiting  rash  diarrhea  hypotension  ...   \n",
       "0           1     0         1            1  ...  \\\n",
       "1           1     0         1            0  ...   \n",
       "2           1     1         1            1  ...   \n",
       "3           0     1         0            1  ...   \n",
       "4           0     0         1            0  ...   \n",
       "..        ...   ...       ...          ...  ...   \n",
       "702         0     0         0            0  ...   \n",
       "703         0     1         1            0  ...   \n",
       "704         0     1         1            1  ...   \n",
       "705         1     0         1            0  ...   \n",
       "706         1     0         0            0  ...   \n",
       "\n",
       "     toenail_loss_or_bullseye_rash  toenail_loss_xor_bullseye_rash   \n",
       "0                                0                               0  \\\n",
       "1                                0                               0   \n",
       "2                                1                               0   \n",
       "3                                0                               0   \n",
       "4                                1                               1   \n",
       "..                             ...                             ...   \n",
       "702                              0                               0   \n",
       "703                              0                               0   \n",
       "704                              0                               0   \n",
       "705                              0                               0   \n",
       "706                              1                               1   \n",
       "\n",
       "     speech_problem_and_bullseye_rash  speech_problem_or_bullseye_rash   \n",
       "0                                   0                                0  \\\n",
       "1                                   0                                0   \n",
       "2                                   1                                1   \n",
       "3                                   0                                0   \n",
       "4                                   0                                0   \n",
       "..                                ...                              ...   \n",
       "702                                 0                                0   \n",
       "703                                 0                                0   \n",
       "704                                 0                                0   \n",
       "705                                 0                                0   \n",
       "706                                 0                                0   \n",
       "\n",
       "     speech_problem_xor_bullseye_rash  c_0  c_1  c_2  c_3  prognosis  \n",
       "0                                   0  707  168  356  112          3  \n",
       "1                                   0   84   36  157  137          7  \n",
       "2                                   0  822  375  496  252          3  \n",
       "3                                   0  640  235  425  252         10  \n",
       "4                                   0   84  147   48   24          6  \n",
       "..                                ...  ...  ...  ...  ...        ...  \n",
       "702                                 0  511  203  409  165          5  \n",
       "703                                 0  503  199  320  163          4  \n",
       "704                                 0  522  174  295  183         10  \n",
       "705                                 0  759  330  367  252          5  \n",
       "706                                 0  342   66   88   44          7  \n",
       "\n",
       "[707 rows x 6117 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_prognosis = train_df[target_column]\n",
    "train_x = train_df.drop(columns=['prognosis'])\n",
    "train_x = cluster_features(train_x)\n",
    "train_x['prognosis'] = col_prognosis\n",
    "train_df = train_x.copy()\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### `Affinity Propagation`\n",
    "\n",
    "Affinity Propagation is a clustering algorithm used in machine learning and data analysis. The algorithm is based on the concept of **message passing** among data points to determine which points should be considered as **exemplars, or representatives**, of clusters. The exemplars are chosen based on their **affinity** or similarity to other data points in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_propagation_features(df):\n",
    "    from sklearn.cluster import AffinityPropagation\n",
    "    from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "    X = manhattan_distances(df)\n",
    "    af = AffinityPropagation(random_state=0, affinity=\"precomputed\").fit(X)\n",
    "    cluster_centers_indices = af.cluster_centers_indices_\n",
    "    n_clusters_ = len(cluster_centers_indices)\n",
    "\n",
    "    df['cluster'] = af.labels_\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>toenail_loss_xor_bullseye_rash</th>\n",
       "      <th>speech_problem_and_bullseye_rash</th>\n",
       "      <th>speech_problem_or_bullseye_rash</th>\n",
       "      <th>speech_problem_xor_bullseye_rash</th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>cluster</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>707</td>\n",
       "      <td>168</td>\n",
       "      <td>356</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>36</td>\n",
       "      <td>157</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>822</td>\n",
       "      <td>375</td>\n",
       "      <td>496</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>235</td>\n",
       "      <td>425</td>\n",
       "      <td>252</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>147</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511</td>\n",
       "      <td>203</td>\n",
       "      <td>409</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>199</td>\n",
       "      <td>320</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>174</td>\n",
       "      <td>295</td>\n",
       "      <td>183</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>759</td>\n",
       "      <td>330</td>\n",
       "      <td>367</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>66</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 6118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain   \n",
       "0               1         1            0           1            1           1  \\\n",
       "1               0         0            0           0            0           0   \n",
       "2               0         1            1           1            0           1   \n",
       "3               0         0            1           1            1           1   \n",
       "4               0         0            0           0            0           0   \n",
       "..            ...       ...          ...         ...          ...         ...   \n",
       "702             0         0            1           1            1           0   \n",
       "703             1         0            1           1            1           1   \n",
       "704             1         0            1           0            1           0   \n",
       "705             1         1            0           0            1           0   \n",
       "706             1         1            0           0            0           0   \n",
       "\n",
       "     vomiting  rash  diarrhea  hypotension  ...   \n",
       "0           1     0         1            1  ...  \\\n",
       "1           1     0         1            0  ...   \n",
       "2           1     1         1            1  ...   \n",
       "3           0     1         0            1  ...   \n",
       "4           0     0         1            0  ...   \n",
       "..        ...   ...       ...          ...  ...   \n",
       "702         0     0         0            0  ...   \n",
       "703         0     1         1            0  ...   \n",
       "704         0     1         1            1  ...   \n",
       "705         1     0         1            0  ...   \n",
       "706         1     0         0            0  ...   \n",
       "\n",
       "     toenail_loss_xor_bullseye_rash  speech_problem_and_bullseye_rash   \n",
       "0                                 0                                 0  \\\n",
       "1                                 0                                 0   \n",
       "2                                 0                                 1   \n",
       "3                                 0                                 0   \n",
       "4                                 1                                 0   \n",
       "..                              ...                               ...   \n",
       "702                               0                                 0   \n",
       "703                               0                                 0   \n",
       "704                               0                                 0   \n",
       "705                               0                                 0   \n",
       "706                               1                                 0   \n",
       "\n",
       "     speech_problem_or_bullseye_rash  speech_problem_xor_bullseye_rash  c_0   \n",
       "0                                  0                                 0  707  \\\n",
       "1                                  0                                 0   84   \n",
       "2                                  1                                 0  822   \n",
       "3                                  0                                 0  640   \n",
       "4                                  0                                 0   84   \n",
       "..                               ...                               ...  ...   \n",
       "702                                0                                 0  511   \n",
       "703                                0                                 0  503   \n",
       "704                                0                                 0  522   \n",
       "705                                0                                 0  759   \n",
       "706                                0                                 0  342   \n",
       "\n",
       "     c_1  c_2  c_3  cluster  prognosis  \n",
       "0    168  356  112        0          3  \n",
       "1     36  157  137        1          7  \n",
       "2    375  496  252        0          3  \n",
       "3    235  425  252        2         10  \n",
       "4    147   48   24        1          6  \n",
       "..   ...  ...  ...      ...        ...  \n",
       "702  203  409  165        1          5  \n",
       "703  199  320  163        1          4  \n",
       "704  174  295  183        2         10  \n",
       "705  330  367  252        0          5  \n",
       "706   66   88   44        1          7  \n",
       "\n",
       "[707 rows x 6118 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_prognosis = train_df[target_column]\n",
    "train_x = train_df.drop(columns=['prognosis'])   \n",
    "train_df = affinity_propagation_features(train_x)\n",
    "train_df['prognosis'] = col_prognosis\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### `Feature Selection`\n",
    "\n",
    "Since the dataset from the previous step contains `6118` features, it was important to utilize a certain number of **most important features** to reduce the computational cost downstream. This was achieved using feature ranking with **recursive feature elimination (`RFE`)**.\n",
    "\n",
    "Using an external estimator (`RandomForestClassifier`), the least significant features are iteratively eliminated. It starts by training an estimator on the full feature set and ranks the features based on their importance. Then, it removes the least important feature(s) and repeats the process until a desired number of features (`n_features_to_select`) is reached. This mitigates over-fitting and improves generalization by focusing on the most informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sudden_fever_xor_muscle_pain', 'sudden_fever_xor_joint_pain',\n",
       "       'sudden_fever_xor_pleural_effusion',\n",
       "       'sudden_fever_xor_weight_loss', 'headache_xor_diarrhea',\n",
       "       'headache_xor_nausea', 'headache_xor_chills',\n",
       "       'headache_xor_fatigue', 'headache_xor_facial_distortion',\n",
       "       'mouth_bleed_xor_joint_pain', 'mouth_bleed_xor_pleural_effusion',\n",
       "       'mouth_bleed_xor_swelling', 'mouth_bleed_xor_nausea',\n",
       "       'mouth_bleed_xor_fatigue', 'mouth_bleed_or_weight_loss',\n",
       "       'mouth_bleed_xor_coma', 'mouth_bleed_xor_irritability',\n",
       "       'nose_bleed_xor_swelling', 'nose_bleed_xor_nausea',\n",
       "       'nose_bleed_xor_digestion_trouble', 'nose_bleed_xor_weight_loss',\n",
       "       'nose_bleed_xor_diziness', 'nose_bleed_xor_loss_of_appetite',\n",
       "       'nose_bleed_xor_microcephaly', 'nose_bleed_or_prostraction',\n",
       "       'muscle_pain_xor_nausea', 'muscle_pain_xor_chills',\n",
       "       'muscle_pain_xor_gum_bleed', 'muscle_pain_xor_jaundice',\n",
       "       'muscle_pain_xor_yellow_skin', 'joint_pain_xor_vomiting',\n",
       "       'joint_pain_xor_weakness', 'joint_pain_xor_red_eyes',\n",
       "       'joint_pain_or_lymph_swells', 'vomiting_xor_rash',\n",
       "       'vomiting_xor_abdominal_pain', 'rash_xor_gastro_bleeding',\n",
       "       'rash_xor_swelling', 'rash_xor_chills',\n",
       "       'rash_xor_light_sensitivity', 'diarrhea_xor_myalgia',\n",
       "       'diarrhea_xor_weight_loss', 'diarrhea_xor_irritability',\n",
       "       'hypotension_xor_digestion_trouble',\n",
       "       'hypotension_xor_stomach_pain', 'hypotension_or_toe_inflammation',\n",
       "       'pleural_effusion_xor_orbital_pain',\n",
       "       'pleural_effusion_xor_neck_pain', 'pleural_effusion_xor_back_pain',\n",
       "       'pleural_effusion_or_itchiness', 'ascites_xor_digestion_trouble',\n",
       "       'ascites_or_skin_lesions', 'ascites_xor_diziness',\n",
       "       'ascites_xor_facial_distortion', 'ascites_xor_microcephaly',\n",
       "       'ascites_or_toenail_loss', 'gastro_bleeding_or_yellow_eyes',\n",
       "       'swelling_xor_chills', 'nausea_xor_weakness',\n",
       "       'myalgia_xor_digestion_trouble',\n",
       "       'digestion_trouble_or_toe_inflammation', 'fatigue_or_tremor',\n",
       "       'skin_lesions_or_yellow_eyes', 'skin_lesions_or_toenail_loss',\n",
       "       'stomach_pain_or_jaundice', 'stomach_pain_or_hypoglycemia',\n",
       "       'stomach_pain_or_itchiness', 'orbital_pain_or_itchiness',\n",
       "       'weakness_or_toenail_loss', 'back_pain_or_yellow_skin',\n",
       "       'back_pain_or_confusion', 'back_pain_or_ulcers',\n",
       "       'weight_loss_or_abdominal_pain', 'weight_loss_or_hyperpyrexia',\n",
       "       'weight_loss_or_stiff_neck', 'jaundice_or_itchiness',\n",
       "       'coma_or_yellow_skin', 'coma_or_itchiness', 'coma_or_ulcers',\n",
       "       'coma_xor_ulcers', 'diziness_or_yellow_skin',\n",
       "       'inflammation_or_itchiness', 'red_eyes_xor_irritability',\n",
       "       'loss_of_appetite_or_light_sensitivity',\n",
       "       'loss_of_appetite_or_hyperpyrexia',\n",
       "       'loss_of_appetite_or_toenail_loss', 'urination_loss_or_anemia',\n",
       "       'slow_heart_rate_or_toenail_loss',\n",
       "       'light_sensitivity_or_stiff_neck', 'yellow_skin_or_irritability',\n",
       "       'yellow_eyes_xor_facial_distortion',\n",
       "       'microcephaly_or_toenail_loss', 'bitter_tongue_or_toenail_loss',\n",
       "       'cocacola_urine_or_toenail_loss', 'hyperpyrexia_or_itchiness',\n",
       "       'c_0', 'c_1', 'c_2', 'c_3', 'cluster'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y = train_df[target_column]\n",
    "X = train_df.drop(columns = [target_column], axis = 1)\n",
    "\n",
    "# executing RFE to reach 100 features by eliminating 20 features in each iteration\n",
    "rfe_selector = RFE(estimator = RandomForestClassifier(), n_features_to_select = 100, step = 20)\n",
    "rfe_selector.fit(X, y)\n",
    "\n",
    "# get the names of most-important features\n",
    "rfe_selector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever_xor_muscle_pain</th>\n",
       "      <th>sudden_fever_xor_joint_pain</th>\n",
       "      <th>sudden_fever_xor_pleural_effusion</th>\n",
       "      <th>sudden_fever_xor_weight_loss</th>\n",
       "      <th>headache_xor_diarrhea</th>\n",
       "      <th>headache_xor_nausea</th>\n",
       "      <th>headache_xor_chills</th>\n",
       "      <th>headache_xor_fatigue</th>\n",
       "      <th>headache_xor_facial_distortion</th>\n",
       "      <th>mouth_bleed_xor_joint_pain</th>\n",
       "      <th>...</th>\n",
       "      <th>microcephaly_or_toenail_loss</th>\n",
       "      <th>bitter_tongue_or_toenail_loss</th>\n",
       "      <th>cocacola_urine_or_toenail_loss</th>\n",
       "      <th>hyperpyrexia_or_itchiness</th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>cluster</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>707</td>\n",
       "      <td>168</td>\n",
       "      <td>356</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>36</td>\n",
       "      <td>157</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>822</td>\n",
       "      <td>375</td>\n",
       "      <td>496</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>235</td>\n",
       "      <td>425</td>\n",
       "      <td>252</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>147</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511</td>\n",
       "      <td>203</td>\n",
       "      <td>409</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>199</td>\n",
       "      <td>320</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>174</td>\n",
       "      <td>295</td>\n",
       "      <td>183</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>759</td>\n",
       "      <td>330</td>\n",
       "      <td>367</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "      <td>66</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever_xor_muscle_pain  sudden_fever_xor_joint_pain   \n",
       "0                               0                            0  \\\n",
       "1                               0                            0   \n",
       "2                               0                            1   \n",
       "3                               1                            1   \n",
       "4                               0                            0   \n",
       "..                            ...                          ...   \n",
       "702                             1                            0   \n",
       "703                             0                            0   \n",
       "704                             0                            1   \n",
       "705                             0                            1   \n",
       "706                             1                            1   \n",
       "\n",
       "     sudden_fever_xor_pleural_effusion  sudden_fever_xor_weight_loss   \n",
       "0                                    0                             0  \\\n",
       "1                                    1                             0   \n",
       "2                                    1                             1   \n",
       "3                                    1                             0   \n",
       "4                                    0                             0   \n",
       "..                                 ...                           ...   \n",
       "702                                  0                             0   \n",
       "703                                  1                             1   \n",
       "704                                  1                             0   \n",
       "705                                  0                             0   \n",
       "706                                  1                             1   \n",
       "\n",
       "     headache_xor_diarrhea  headache_xor_nausea  headache_xor_chills   \n",
       "0                        0                    0                    0  \\\n",
       "1                        1                    1                    0   \n",
       "2                        0                    0                    0   \n",
       "3                        0                    1                    1   \n",
       "4                        1                    0                    0   \n",
       "..                     ...                  ...                  ...   \n",
       "702                      0                    0                    0   \n",
       "703                      1                    1                    0   \n",
       "704                      1                    1                    1   \n",
       "705                      0                    0                    0   \n",
       "706                      1                    1                    1   \n",
       "\n",
       "     headache_xor_fatigue  headache_xor_facial_distortion   \n",
       "0                       0                               1  \\\n",
       "1                       0                               0   \n",
       "2                       0                               0   \n",
       "3                       1                               1   \n",
       "4                       0                               0   \n",
       "..                    ...                             ...   \n",
       "702                     0                               1   \n",
       "703                     0                               1   \n",
       "704                     1                               1   \n",
       "705                     0                               1   \n",
       "706                     1                               0   \n",
       "\n",
       "     mouth_bleed_xor_joint_pain  ...  microcephaly_or_toenail_loss   \n",
       "0                             1  ...                             0  \\\n",
       "1                             0  ...                             0   \n",
       "2                             0  ...                             1   \n",
       "3                             0  ...                             0   \n",
       "4                             0  ...                             1   \n",
       "..                          ...  ...                           ...   \n",
       "702                           1  ...                             1   \n",
       "703                           0  ...                             1   \n",
       "704                           1  ...                             1   \n",
       "705                           0  ...                             1   \n",
       "706                           0  ...                             1   \n",
       "\n",
       "     bitter_tongue_or_toenail_loss  cocacola_urine_or_toenail_loss   \n",
       "0                                1                               0  \\\n",
       "1                                0                               0   \n",
       "2                                1                               1   \n",
       "3                                0                               0   \n",
       "4                                1                               1   \n",
       "..                             ...                             ...   \n",
       "702                              0                               0   \n",
       "703                              0                               0   \n",
       "704                              1                               0   \n",
       "705                              1                               0   \n",
       "706                              1                               1   \n",
       "\n",
       "     hyperpyrexia_or_itchiness  c_0  c_1  c_2  c_3  cluster  prognosis  \n",
       "0                            0  707  168  356  112        0          3  \n",
       "1                            0   84   36  157  137        1          7  \n",
       "2                            1  822  375  496  252        0          3  \n",
       "3                            0  640  235  425  252        2         10  \n",
       "4                            1   84  147   48   24        1          6  \n",
       "..                         ...  ...  ...  ...  ...      ...        ...  \n",
       "702                          0  511  203  409  165        1          5  \n",
       "703                          0  503  199  320  163        1          4  \n",
       "704                          0  522  174  295  183        2         10  \n",
       "705                          0  759  330  367  252        0          5  \n",
       "706                          1  342   66   88   44        1          7  \n",
       "\n",
       "[707 rows x 101 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling the dataset based on only the important features\n",
    "train_df = train_df[rfe_selector.get_feature_names_out()]\n",
    "train_df['prognosis'] = y\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Dimensionality Reduction: `Principle Component Analysis`\n",
    "\n",
    "To further reduce the the load on computational resources and training times (*curse of dimensionilty*), **Dimensionality Reduction** can be utilized.\n",
    "\n",
    "**Principle Component Analysis (PCA)** is a linear dimensionality reduction technique, which takes advantage of existing correlations between the correlated features in the dataset, and combines them into a new set (`n_components`) of uncorrelated variables. PCA is an unsupervised algorithm as it does not require labels in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# X = train_df.drop(columns=[target_column], axis=1)\n",
    "\n",
    "# pca = PCA(n_components=30, random_state=42)\n",
    "# X_with_PCA = pca.fit_transform(X)\n",
    "\n",
    "# print(f'{X_with_PCA.shape}')\n",
    "\n",
    "# train_df = pd.DataFrame(X_with_PCA)\n",
    "# train_df['prognosis'] = y\n",
    "\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Dimensionality Reduction: `Linear Discriminant Analysis`\n",
    "\n",
    "Another method of dimensionality reduction using **Linear Discriminant Analysis (LDA)** involves reducing the number of features in a dataset while preserving the discriminative information between different classes. It works by calculating summary statistics for the input features by class label, and therefore is a method of supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707, 10)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.982106</td>\n",
       "      <td>-1.132549</td>\n",
       "      <td>-4.091500</td>\n",
       "      <td>-0.024386</td>\n",
       "      <td>-0.095186</td>\n",
       "      <td>-1.939725</td>\n",
       "      <td>1.344869</td>\n",
       "      <td>1.440609</td>\n",
       "      <td>-0.509831</td>\n",
       "      <td>0.298631</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.296227</td>\n",
       "      <td>0.623122</td>\n",
       "      <td>0.192366</td>\n",
       "      <td>0.344144</td>\n",
       "      <td>0.817654</td>\n",
       "      <td>0.643473</td>\n",
       "      <td>1.016322</td>\n",
       "      <td>0.940847</td>\n",
       "      <td>-1.011755</td>\n",
       "      <td>-2.553194</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.180573</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>-2.619842</td>\n",
       "      <td>1.008916</td>\n",
       "      <td>-0.945169</td>\n",
       "      <td>0.090492</td>\n",
       "      <td>-0.276080</td>\n",
       "      <td>0.723454</td>\n",
       "      <td>-0.648361</td>\n",
       "      <td>-0.584534</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.293667</td>\n",
       "      <td>-0.406778</td>\n",
       "      <td>-0.163848</td>\n",
       "      <td>1.273316</td>\n",
       "      <td>-1.478024</td>\n",
       "      <td>1.421692</td>\n",
       "      <td>0.721753</td>\n",
       "      <td>-0.604970</td>\n",
       "      <td>-1.185534</td>\n",
       "      <td>1.542986</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.824343</td>\n",
       "      <td>-2.953012</td>\n",
       "      <td>-1.646507</td>\n",
       "      <td>-0.401096</td>\n",
       "      <td>-0.895644</td>\n",
       "      <td>0.780135</td>\n",
       "      <td>1.179457</td>\n",
       "      <td>-0.669946</td>\n",
       "      <td>-0.979475</td>\n",
       "      <td>0.435173</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>1.670677</td>\n",
       "      <td>-0.096094</td>\n",
       "      <td>0.855837</td>\n",
       "      <td>0.523036</td>\n",
       "      <td>0.372486</td>\n",
       "      <td>0.476263</td>\n",
       "      <td>-0.812319</td>\n",
       "      <td>-1.440670</td>\n",
       "      <td>-0.594341</td>\n",
       "      <td>-1.862021</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>0.355360</td>\n",
       "      <td>1.149663</td>\n",
       "      <td>0.492379</td>\n",
       "      <td>0.450134</td>\n",
       "      <td>0.063441</td>\n",
       "      <td>2.178120</td>\n",
       "      <td>-0.417102</td>\n",
       "      <td>1.073401</td>\n",
       "      <td>0.204671</td>\n",
       "      <td>-0.371528</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1.355306</td>\n",
       "      <td>0.481932</td>\n",
       "      <td>1.850842</td>\n",
       "      <td>0.981263</td>\n",
       "      <td>-1.375054</td>\n",
       "      <td>-0.203842</td>\n",
       "      <td>-1.581311</td>\n",
       "      <td>1.082506</td>\n",
       "      <td>1.277459</td>\n",
       "      <td>0.506788</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1.967637</td>\n",
       "      <td>1.667985</td>\n",
       "      <td>-1.249968</td>\n",
       "      <td>1.114659</td>\n",
       "      <td>-1.165443</td>\n",
       "      <td>-0.708010</td>\n",
       "      <td>-0.453460</td>\n",
       "      <td>-0.312226</td>\n",
       "      <td>-1.596543</td>\n",
       "      <td>0.289125</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>-1.737200</td>\n",
       "      <td>-2.999715</td>\n",
       "      <td>-0.241391</td>\n",
       "      <td>-1.764582</td>\n",
       "      <td>-1.281260</td>\n",
       "      <td>1.482130</td>\n",
       "      <td>-1.120404</td>\n",
       "      <td>-0.370946</td>\n",
       "      <td>0.482135</td>\n",
       "      <td>-0.307856</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \n",
       "0    0.982106 -1.132549 -4.091500 -0.024386 -0.095186 -1.939725  1.344869  \\\n",
       "1   -3.296227  0.623122  0.192366  0.344144  0.817654  0.643473  1.016322   \n",
       "2    3.180573  0.015735 -2.619842  1.008916 -0.945169  0.090492 -0.276080   \n",
       "3    2.293667 -0.406778 -0.163848  1.273316 -1.478024  1.421692  0.721753   \n",
       "4   -0.824343 -2.953012 -1.646507 -0.401096 -0.895644  0.780135  1.179457   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "702  1.670677 -0.096094  0.855837  0.523036  0.372486  0.476263 -0.812319   \n",
       "703  0.355360  1.149663  0.492379  0.450134  0.063441  2.178120 -0.417102   \n",
       "704  1.355306  0.481932  1.850842  0.981263 -1.375054 -0.203842 -1.581311   \n",
       "705  1.967637  1.667985 -1.249968  1.114659 -1.165443 -0.708010 -0.453460   \n",
       "706 -1.737200 -2.999715 -0.241391 -1.764582 -1.281260  1.482130 -1.120404   \n",
       "\n",
       "            7         8         9  prognosis  \n",
       "0    1.440609 -0.509831  0.298631          3  \n",
       "1    0.940847 -1.011755 -2.553194          7  \n",
       "2    0.723454 -0.648361 -0.584534          3  \n",
       "3   -0.604970 -1.185534  1.542986         10  \n",
       "4   -0.669946 -0.979475  0.435173          6  \n",
       "..        ...       ...       ...        ...  \n",
       "702 -1.440670 -0.594341 -1.862021          5  \n",
       "703  1.073401  0.204671 -0.371528          4  \n",
       "704  1.082506  1.277459  0.506788         10  \n",
       "705 -0.312226 -1.596543  0.289125          5  \n",
       "706 -0.370946  0.482135 -0.307856          7  \n",
       "\n",
       "[707 rows x 11 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "y = train_df[target_column]\n",
    "X = train_df.drop(columns=[target_column], axis=1)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_with_LDA = lda.fit_transform(X, y)\n",
    "\n",
    "print(f'{X_with_LDA.shape}\\n')\n",
    "\n",
    "train_df = pd.DataFrame(X_with_LDA)\n",
    "\n",
    "train_df['prognosis'] = y\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### `class_weights` for training data\n",
    "\n",
    "To reduce the impact of *class imbalance* (some classes being more prevelant than the others), **class weights** are introduced. Class weights assign different weights to different classes, affecting the contribution of each class to the overall loss function or optimization process during training. By giving more weight to the minority class and less weight to the majority class, the algorithm pays more attention to the minority class samples and tries to correct the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weights (target):\n",
    "    \n",
    "    class_sample_count = np.unique(target, return_counts=True)[1]\n",
    "    total_samples = len(target)\n",
    "\n",
    "    train_class_weight = 1 - (class_sample_count/total_samples)\n",
    "\n",
    "    train_class_weight = torch.from_numpy(train_class_weight).type(torch.float).to(device)\n",
    "\n",
    "    return train_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "## 3. `optuna` Hyper-Parameter Tuning\n",
    "\n",
    "Optuna is an open-source black-box hyperparameter optimization framework, designed to automate the process of hyperparameter tuning. Optuna allows easy integration with PyTorch in order to obtain optimized neural network structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Simple MLP model with tune-able parameters\n",
    "\n",
    "Defining a basic multi-layer perceptron (MLP) structure for hyperparameter tuning. During every `trial` of the tuning process, a new `custom_model` with a fresh set of parameters is generated and evaluated for the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model (trial, feature_in, feature_out=11): \n",
    "\n",
    "    # number of hidden layers (-1 for input layer)\n",
    "    num_layers = trial.suggest_int('Number of layers', 2, 5, step=1)\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    num_input = feature_in\n",
    "\n",
    "    for i in range(num_layers):\n",
    "\n",
    "        # number of hidden neurons\n",
    "        num_output = trial.suggest_int('num_l{}'.format(i), 4, 9, step=1)\n",
    "        num_output = 2 ** num_output\n",
    "\n",
    "        layers.append(nn.Linear(in_features=num_input, out_features=num_output))\n",
    "        layers.append(nn.BatchNorm1d(num_output))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        # dropout probability for the layer\n",
    "        prb = trial.suggest_float('dropout_prb_l{}'.format(i), 0., 1., step=0.2)\n",
    "        layers.append(nn.Dropout(p=prb))\n",
    "\n",
    "        num_input = num_output\n",
    "\n",
    "    layers.append(nn.Linear(in_features=num_input, out_features=feature_out))\n",
    "\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Helper function to reset model weights in every fold of training\n",
    "\n",
    "Since the tuning process optimizes on the average k-fold `map@k` score, this function is used to reset the model weights before starting a new fold, in order to avoid over-training and over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "global X, y\n",
    "\n",
    "X = train_df.drop(columns=[target_column])\n",
    "y = train_df[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "This `train_mapk` training process is used in every trial of the tuning process.\n",
    "\n",
    "1. Whenever a new `trial` is initiated, a new `model` (defined in the function `custom_model`) is created. \n",
    "2. Optuna then *suggests* a fresh set of *tune-able parameters* for this trial.\n",
    "3. The complete `train_df` dataset is then sampled using `5-fold`, and `train` and `test` data are produced for each fold.\n",
    "4. For each `fold`, the generated model and the suggested parameters are used for training, and obtaining `5-fold map@k` score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "The `map@k` or **Mean Average Precision at K** an error metric that can be used when the sequence of your predictions plays an important role in the objective of the task. In our objective, since it is desired to know whether the correctly predicted prognosis is within the top `k =3` predictions, `map@k` is a suitable metric to use for oprimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mapk (model, trial):\n",
    "\n",
    "    # number of epochs in a trial\n",
    "    epochs = trial.suggest_int('epochs', 500, 1000, step=100)\n",
    "\n",
    "    # executing k-fold cross validation optimization\n",
    "    k = 5\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "\n",
    "\n",
    "    # tuning the optimizer and its learning rate\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\", \"AdamW\", \"Adamax\", \"NAdam\"])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "\n",
    "    optimizer = getattr(optim, optimizer)(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "    # device agnostics\n",
    "    if torch.cuda.is_available(): \n",
    "        model = model.cuda()\n",
    "\n",
    "\n",
    "    # empty list to store 'k' map@k scores for each fold\n",
    "    mapk_list = []\n",
    "\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        \n",
    "        # new train and test data in each fold\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "\n",
    "        # calculating class_weights for training data in each fold\n",
    "        train_class_weight = apply_weights(y_train)\n",
    "\n",
    "\n",
    "        # for multi-class classification problem\n",
    "        loss_function = nn.CrossEntropyLoss(weight=train_class_weight)\n",
    "\n",
    "        # device agnostics\n",
    "        if torch.cuda.is_available(): \n",
    "            loss_function = loss_function.cuda()\n",
    "\n",
    "\n",
    "        # making tensors for train and test data in each fold\n",
    "        X_train_tensor = torch.from_numpy(X_train.values).type(torch.float).to(device)\n",
    "        y_train_tensor = torch.from_numpy(y_train.values).type(torch.LongTensor).to(device)\n",
    "\n",
    "        X_test_tensor = torch.from_numpy(X_test.values).type(torch.float).to(device)\n",
    "        y_test_tensor = torch.from_numpy(y_test.values).type(torch.LongTensor).to(device)\n",
    "\n",
    "\n",
    "        # resetting model weights before starting training for the next fold\n",
    "        model.apply(weight_reset)\n",
    "\n",
    "\n",
    "        # training loop for epochs for particular trial\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # enter training mode\n",
    "            model.train()\n",
    "\n",
    "            # getting raw prediction outputs from the NN with tuned parameters\n",
    "            y_train_logits = model(X_train_tensor)\n",
    "\n",
    "            # converting raw logits to probabilities for each class\n",
    "            y_train_pred_probs = torch.softmax(y_train_logits, dim=1)\n",
    "\n",
    "            # improving model weights using gradient-based optimization\n",
    "            loss = loss_function(y_train_logits, y_train_tensor)\n",
    "\n",
    "            # zero-out the gradients of parameters before next pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # perform back-prop\n",
    "            loss.backward()\n",
    "\n",
    "            # update model paramters using calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        # enter testing mode\n",
    "        model.eval()\n",
    "        \n",
    "        # getting raw test predictions\n",
    "        y_test_logits = model(X_test_tensor).to(device)\n",
    "\n",
    "        # converting them to class probabilities \n",
    "        y_test_pred_probs = torch.softmax(y_test_logits, dim=1)\n",
    "\n",
    "        # converting tensors into numpy array to calculate map@k score for this fold\n",
    "        y_test_pred_probs = y_test_pred_probs.cpu()\n",
    "        y_test_pred_probs = y_test_pred_probs.detach().numpy()\n",
    "\n",
    "\n",
    "        mapk_list.append(mapk_score(y_test, y_test_pred_probs))\n",
    "\n",
    "\n",
    "    # getting average map@k score of k-folds\n",
    "    cv_mapk = np.average(mapk_list)\n",
    "    print(f'---------------------------------------------\\n{k}-fold Validation MAPK: {cv_mapk}\\n\\n')\n",
    "\n",
    "    return cv_mapk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Objective function to optimize\n",
    "\n",
    "The `objective_function` is reponsible for initializing a new neural network structure (`custom_model`) and calls the training loop (`train_mapk`). It then receives the `average map@k` score which is used by optuna for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = train_df.shape[1] - 1\n",
    "\n",
    "def objective_function (trial):\n",
    "\n",
    "    # tune-able MLP model\n",
    "    model = custom_model(trial=trial, feature_in=n_features, feature_out=11)\n",
    "\n",
    "    # tuning on average map@k of k-fold obtained after training loop\n",
    "    cv_mapk = train_mapk(model, trial)\n",
    "\n",
    "    return cv_mapk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Creating `optuna study` and optimizing\n",
    "\n",
    "In optuna, `study` refers to a variable that can store and represent a collection of `trails` and their results. We optimizing using the output obtained from the `objective_function` for a fixed number of trials (`n_trials`). \n",
    "\n",
    "`direction=\"maximize\"` represnts that optuna maximizes the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:18:39,227] A new study created in memory with name: no-name-804d841e-b0c0-4818-a378-b3760710c171\n",
      "[I 2023-07-15 20:18:45,435] Trial 0 finished with value: 0.5262244863982952 and parameters: {'Number of layers': 2, 'num_l0': 6, 'dropout_prb_l0': 0.4, 'num_l1': 4, 'dropout_prb_l1': 0.2, 'epochs': 700, 'optimizer': 'SGD', 'learning_rate': 0.006582964738854893}. Best is trial 0 with value: 0.5262244863982952.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5262244863982952\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:19:09,264] Trial 1 finished with value: 0.5513684946558786 and parameters: {'Number of layers': 5, 'num_l0': 7, 'dropout_prb_l0': 0.0, 'num_l1': 9, 'dropout_prb_l1': 0.4, 'num_l2': 6, 'dropout_prb_l2': 0.0, 'num_l3': 7, 'dropout_prb_l3': 0.0, 'num_l4': 9, 'dropout_prb_l4': 0.0, 'epochs': 800, 'optimizer': 'Adamax', 'learning_rate': 0.0022747201708553286}. Best is trial 1 with value: 0.5513684946558786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5513684946558786\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:19:17,332] Trial 2 finished with value: 0.19163919688342823 and parameters: {'Number of layers': 3, 'num_l0': 7, 'dropout_prb_l0': 0.8, 'num_l1': 7, 'dropout_prb_l1': 0.4, 'num_l2': 5, 'dropout_prb_l2': 1.0, 'epochs': 600, 'optimizer': 'Adam', 'learning_rate': 0.001389218046260309}. Best is trial 1 with value: 0.5513684946558786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.19163919688342823\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:19:30,883] Trial 3 finished with value: 0.10846735257882996 and parameters: {'Number of layers': 4, 'num_l0': 9, 'dropout_prb_l0': 0.6000000000000001, 'num_l1': 9, 'dropout_prb_l1': 1.0, 'num_l2': 4, 'dropout_prb_l2': 1.0, 'num_l3': 5, 'dropout_prb_l3': 0.4, 'epochs': 900, 'optimizer': 'RMSprop', 'learning_rate': 0.00014041730673531601}. Best is trial 1 with value: 0.5513684946558786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.10846735257882996\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:19:37,416] Trial 4 finished with value: 0.13997436153564413 and parameters: {'Number of layers': 2, 'num_l0': 9, 'dropout_prb_l0': 1.0, 'num_l1': 8, 'dropout_prb_l1': 1.0, 'epochs': 600, 'optimizer': 'NAdam', 'learning_rate': 0.00017667427597676454}. Best is trial 1 with value: 0.5513684946558786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.13997436153564413\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:19:43,142] Trial 5 finished with value: 0.12216395298504978 and parameters: {'Number of layers': 3, 'num_l0': 7, 'dropout_prb_l0': 0.4, 'num_l1': 6, 'dropout_prb_l1': 1.0, 'num_l2': 4, 'dropout_prb_l2': 0.8, 'epochs': 500, 'optimizer': 'SGD', 'learning_rate': 0.020721499712082918}. Best is trial 1 with value: 0.5513684946558786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.12216395298504978\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:19:50,448] Trial 6 finished with value: 0.5613225452002796 and parameters: {'Number of layers': 2, 'num_l0': 4, 'dropout_prb_l0': 0.6000000000000001, 'num_l1': 9, 'dropout_prb_l1': 0.4, 'epochs': 700, 'optimizer': 'Adam', 'learning_rate': 0.00013620675276101513}. Best is trial 6 with value: 0.5613225452002796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5613225452002796\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:20:15,975] Trial 7 finished with value: 0.21852295807944594 and parameters: {'Number of layers': 4, 'num_l0': 5, 'dropout_prb_l0': 0.8, 'num_l1': 6, 'dropout_prb_l1': 0.6000000000000001, 'num_l2': 5, 'dropout_prb_l2': 0.8, 'num_l3': 6, 'dropout_prb_l3': 0.4, 'epochs': 1000, 'optimizer': 'Adamax', 'learning_rate': 0.00030938742225466775}. Best is trial 6 with value: 0.5613225452002796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.21852295807944594\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:20:27,119] Trial 8 finished with value: 0.14421469716645025 and parameters: {'Number of layers': 4, 'num_l0': 6, 'dropout_prb_l0': 0.4, 'num_l1': 7, 'dropout_prb_l1': 0.2, 'num_l2': 5, 'dropout_prb_l2': 0.6000000000000001, 'num_l3': 4, 'dropout_prb_l3': 1.0, 'epochs': 800, 'optimizer': 'SGD', 'learning_rate': 0.0007159095266876948}. Best is trial 6 with value: 0.5613225452002796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.14421469716645025\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:20:40,235] Trial 9 finished with value: 0.13649485565877534 and parameters: {'Number of layers': 3, 'num_l0': 8, 'dropout_prb_l0': 1.0, 'num_l1': 4, 'dropout_prb_l1': 0.0, 'num_l2': 8, 'dropout_prb_l2': 0.6000000000000001, 'epochs': 1000, 'optimizer': 'Adam', 'learning_rate': 0.0001355719491118981}. Best is trial 6 with value: 0.5613225452002796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.13649485565877534\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:20:47,344] Trial 10 finished with value: 0.4362168281556954 and parameters: {'Number of layers': 2, 'num_l0': 4, 'dropout_prb_l0': 0.0, 'num_l1': 8, 'dropout_prb_l1': 0.6000000000000001, 'epochs': 700, 'optimizer': 'AdamW', 'learning_rate': 1.238194155414651e-05}. Best is trial 6 with value: 0.5613225452002796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.4362168281556954\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:21:11,293] Trial 11 finished with value: 0.5111377484766756 and parameters: {'Number of layers': 5, 'num_l0': 4, 'dropout_prb_l0': 0.0, 'num_l1': 9, 'dropout_prb_l1': 0.4, 'num_l2': 8, 'dropout_prb_l2': 0.0, 'num_l3': 9, 'dropout_prb_l3': 0.0, 'num_l4': 9, 'dropout_prb_l4': 0.0, 'epochs': 800, 'optimizer': 'Adamax', 'learning_rate': 0.07548627584913152}. Best is trial 6 with value: 0.5613225452002796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5111377484766756\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:21:37,842] Trial 12 finished with value: 0.5521160057270336 and parameters: {'Number of layers': 5, 'num_l0': 5, 'dropout_prb_l0': 0.2, 'num_l1': 9, 'dropout_prb_l1': 0.6000000000000001, 'num_l2': 7, 'dropout_prb_l2': 0.0, 'num_l3': 8, 'dropout_prb_l3': 0.0, 'num_l4': 8, 'dropout_prb_l4': 0.6000000000000001, 'epochs': 900, 'optimizer': 'Adamax', 'learning_rate': 0.0033336189626411122}. Best is trial 6 with value: 0.5613225452002796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5521160057270336\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:21:55,024] Trial 13 finished with value: 0.20294842340092564 and parameters: {'Number of layers': 5, 'num_l0': 5, 'dropout_prb_l0': 0.2, 'num_l1': 8, 'dropout_prb_l1': 0.8, 'num_l2': 9, 'dropout_prb_l2': 0.2, 'num_l3': 8, 'dropout_prb_l3': 0.8, 'num_l4': 5, 'dropout_prb_l4': 1.0, 'epochs': 900, 'optimizer': 'Adam', 'learning_rate': 0.004998163116188949}. Best is trial 6 with value: 0.5613225452002796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.20294842340092564\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:22:10,211] Trial 14 finished with value: 0.5759298105417374 and parameters: {'Number of layers': 4, 'num_l0': 5, 'dropout_prb_l0': 0.2, 'num_l1': 9, 'dropout_prb_l1': 0.8, 'num_l2': 7, 'dropout_prb_l2': 0.2, 'num_l3': 9, 'dropout_prb_l3': 0.2, 'epochs': 900, 'optimizer': 'NAdam', 'learning_rate': 0.0005259364536456692}. Best is trial 14 with value: 0.5759298105417374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5759298105417374\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:22:19,658] Trial 15 finished with value: 0.2936136916059001 and parameters: {'Number of layers': 3, 'num_l0': 4, 'dropout_prb_l0': 0.6000000000000001, 'num_l1': 5, 'dropout_prb_l1': 0.8, 'num_l2': 7, 'dropout_prb_l2': 0.4, 'epochs': 600, 'optimizer': 'NAdam', 'learning_rate': 3.63852069977877e-05}. Best is trial 14 with value: 0.5759298105417374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.2936136916059001\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:22:33,800] Trial 16 finished with value: 0.595719708320847 and parameters: {'Number of layers': 4, 'num_l0': 5, 'dropout_prb_l0': 0.2, 'num_l1': 8, 'dropout_prb_l1': 0.8, 'num_l2': 9, 'dropout_prb_l2': 0.4, 'num_l3': 9, 'dropout_prb_l3': 0.6000000000000001, 'epochs': 700, 'optimizer': 'NAdam', 'learning_rate': 0.0006127721345515839}. Best is trial 16 with value: 0.595719708320847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.595719708320847\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:22:51,590] Trial 17 finished with value: 0.5945276862118336 and parameters: {'Number of layers': 4, 'num_l0': 6, 'dropout_prb_l0': 0.2, 'num_l1': 8, 'dropout_prb_l1': 0.8, 'num_l2': 9, 'dropout_prb_l2': 0.4, 'num_l3': 9, 'dropout_prb_l3': 0.6000000000000001, 'epochs': 900, 'optimizer': 'NAdam', 'learning_rate': 0.0005107672418175951}. Best is trial 16 with value: 0.595719708320847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5945276862118336\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:23:01,643] Trial 18 finished with value: 0.6030250058269238 and parameters: {'Number of layers': 4, 'num_l0': 6, 'dropout_prb_l0': 0.2, 'num_l1': 7, 'dropout_prb_l1': 0.8, 'num_l2': 9, 'dropout_prb_l2': 0.4, 'num_l3': 9, 'dropout_prb_l3': 0.6000000000000001, 'epochs': 500, 'optimizer': 'NAdam', 'learning_rate': 0.0008248083168994686}. Best is trial 18 with value: 0.6030250058269238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.6030250058269238\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:23:11,545] Trial 19 finished with value: 0.5820564046215829 and parameters: {'Number of layers': 4, 'num_l0': 8, 'dropout_prb_l0': 0.2, 'num_l1': 7, 'dropout_prb_l1': 0.8, 'num_l2': 9, 'dropout_prb_l2': 0.4, 'num_l3': 7, 'dropout_prb_l3': 0.6000000000000001, 'epochs': 500, 'optimizer': 'NAdam', 'learning_rate': 0.0009291763078789745}. Best is trial 18 with value: 0.6030250058269238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5820564046215829\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:23:18,476] Trial 20 finished with value: 0.16218326507508407 and parameters: {'Number of layers': 3, 'num_l0': 6, 'dropout_prb_l0': 0.0, 'num_l1': 6, 'dropout_prb_l1': 1.0, 'num_l2': 8, 'dropout_prb_l2': 0.2, 'epochs': 500, 'optimizer': 'RMSprop', 'learning_rate': 0.0014091794446125941}. Best is trial 18 with value: 0.6030250058269238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.16218326507508407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:23:30,567] Trial 21 finished with value: 0.6006742583158526 and parameters: {'Number of layers': 4, 'num_l0': 6, 'dropout_prb_l0': 0.2, 'num_l1': 8, 'dropout_prb_l1': 0.8, 'num_l2': 9, 'dropout_prb_l2': 0.4, 'num_l3': 9, 'dropout_prb_l3': 0.6000000000000001, 'epochs': 600, 'optimizer': 'NAdam', 'learning_rate': 0.0003997812460269745}. Best is trial 18 with value: 0.6030250058269238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.6006742583158526\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:23:42,224] Trial 22 finished with value: 0.5857906303066626 and parameters: {'Number of layers': 4, 'num_l0': 5, 'dropout_prb_l0': 0.4, 'num_l1': 7, 'dropout_prb_l1': 0.6000000000000001, 'num_l2': 9, 'dropout_prb_l2': 0.6000000000000001, 'num_l3': 8, 'dropout_prb_l3': 0.8, 'epochs': 600, 'optimizer': 'NAdam', 'learning_rate': 0.00036041238245044805}. Best is trial 18 with value: 0.6030250058269238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5857906303066626\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:23:52,240] Trial 23 finished with value: 0.5773266073985284 and parameters: {'Number of layers': 4, 'num_l0': 6, 'dropout_prb_l0': 0.2, 'num_l1': 8, 'dropout_prb_l1': 0.8, 'num_l2': 8, 'dropout_prb_l2': 0.4, 'num_l3': 9, 'dropout_prb_l3': 0.6000000000000001, 'epochs': 500, 'optimizer': 'NAdam', 'learning_rate': 0.001703538689336328}. Best is trial 18 with value: 0.6030250058269238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5773266073985284\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:24:06,478] Trial 24 finished with value: 0.11835980421536312 and parameters: {'Number of layers': 5, 'num_l0': 7, 'dropout_prb_l0': 0.0, 'num_l1': 7, 'dropout_prb_l1': 1.0, 'num_l2': 9, 'dropout_prb_l2': 0.2, 'num_l3': 8, 'dropout_prb_l3': 0.8, 'num_l4': 4, 'dropout_prb_l4': 1.0, 'epochs': 600, 'optimizer': 'AdamW', 'learning_rate': 6.192774460092326e-05}. Best is trial 18 with value: 0.6030250058269238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.11835980421536312\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:24:20,147] Trial 25 finished with value: 0.5929061365830919 and parameters: {'Number of layers': 4, 'num_l0': 5, 'dropout_prb_l0': 0.4, 'num_l1': 8, 'dropout_prb_l1': 0.6000000000000001, 'num_l2': 8, 'dropout_prb_l2': 0.4, 'num_l3': 9, 'dropout_prb_l3': 0.4, 'epochs': 700, 'optimizer': 'NAdam', 'learning_rate': 0.0007833497276602595}. Best is trial 18 with value: 0.6030250058269238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5929061365830919\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:24:30,016] Trial 26 finished with value: 0.6103502813571737 and parameters: {'Number of layers': 3, 'num_l0': 6, 'dropout_prb_l0': 0.2, 'num_l1': 8, 'dropout_prb_l1': 0.8, 'num_l2': 9, 'dropout_prb_l2': 0.6000000000000001, 'epochs': 600, 'optimizer': 'NAdam', 'learning_rate': 0.00029251829990271515}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.6103502813571737\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:24:37,879] Trial 27 finished with value: 0.5417174441447741 and parameters: {'Number of layers': 3, 'num_l0': 6, 'dropout_prb_l0': 0.2, 'num_l1': 5, 'dropout_prb_l1': 0.8, 'num_l2': 8, 'dropout_prb_l2': 0.8, 'epochs': 500, 'optimizer': 'NAdam', 'learning_rate': 0.00026478454663963287}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5417174441447741\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:24:48,171] Trial 28 finished with value: 0.20296673658975126 and parameters: {'Number of layers': 3, 'num_l0': 8, 'dropout_prb_l0': 0.4, 'num_l1': 7, 'dropout_prb_l1': 1.0, 'num_l2': 9, 'dropout_prb_l2': 0.6000000000000001, 'epochs': 600, 'optimizer': 'NAdam', 'learning_rate': 0.00030683621456984}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.20296673658975126\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:24:56,124] Trial 29 finished with value: 0.5535194619252156 and parameters: {'Number of layers': 3, 'num_l0': 6, 'dropout_prb_l0': 0.0, 'num_l1': 6, 'dropout_prb_l1': 0.6000000000000001, 'num_l2': 6, 'dropout_prb_l2': 0.6000000000000001, 'epochs': 500, 'optimizer': 'AdamW', 'learning_rate': 0.0025579809746693314}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5535194619252156\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:25:02,553] Trial 30 finished with value: 0.5742949422302134 and parameters: {'Number of layers': 2, 'num_l0': 7, 'dropout_prb_l0': 0.4, 'num_l1': 8, 'dropout_prb_l1': 0.0, 'epochs': 600, 'optimizer': 'RMSprop', 'learning_rate': 0.0011731148766188015}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5742949422302134\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:25:16,517] Trial 31 finished with value: 0.5971248293543768 and parameters: {'Number of layers': 4, 'num_l0': 6, 'dropout_prb_l0': 0.2, 'num_l1': 8, 'dropout_prb_l1': 0.8, 'num_l2': 9, 'dropout_prb_l2': 0.4, 'num_l3': 8, 'dropout_prb_l3': 0.6000000000000001, 'epochs': 700, 'optimizer': 'NAdam', 'learning_rate': 0.000636284276587048}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5971248293543768\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:25:28,652] Trial 32 finished with value: 0.5886508174341557 and parameters: {'Number of layers': 4, 'num_l0': 6, 'dropout_prb_l0': 0.2, 'num_l1': 8, 'dropout_prb_l1': 0.8, 'num_l2': 9, 'dropout_prb_l2': 0.2, 'num_l3': 8, 'dropout_prb_l3': 0.8, 'epochs': 600, 'optimizer': 'NAdam', 'learning_rate': 0.0009210898611414243}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5886508174341557\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:25:45,186] Trial 33 finished with value: 0.17157959577797754 and parameters: {'Number of layers': 5, 'num_l0': 7, 'dropout_prb_l0': 0.0, 'num_l1': 7, 'dropout_prb_l1': 0.8, 'num_l2': 9, 'dropout_prb_l2': 0.4, 'num_l3': 7, 'dropout_prb_l3': 1.0, 'num_l4': 6, 'dropout_prb_l4': 0.4, 'epochs': 700, 'optimizer': 'NAdam', 'learning_rate': 0.0029991376657925004}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.17157959577797754\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:25:56,921] Trial 34 finished with value: 0.43035161322545196 and parameters: {'Number of layers': 4, 'num_l0': 6, 'dropout_prb_l0': 0.2, 'num_l1': 7, 'dropout_prb_l1': 0.6000000000000001, 'num_l2': 8, 'dropout_prb_l2': 0.6000000000000001, 'num_l3': 8, 'dropout_prb_l3': 0.4, 'epochs': 700, 'optimizer': 'SGD', 'learning_rate': 0.0015389214203553015}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.43035161322545196\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:26:06,731] Trial 35 finished with value: 0.1817583990943296 and parameters: {'Number of layers': 3, 'num_l0': 7, 'dropout_prb_l0': 0.4, 'num_l1': 9, 'dropout_prb_l1': 1.0, 'num_l2': 9, 'dropout_prb_l2': 0.4, 'epochs': 600, 'optimizer': 'NAdam', 'learning_rate': 0.000446709959495983}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.1817583990943296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:26:17,301] Trial 36 finished with value: 0.5737871674491394 and parameters: {'Number of layers': 4, 'num_l0': 6, 'dropout_prb_l0': 0.0, 'num_l1': 8, 'dropout_prb_l1': 0.2, 'num_l2': 8, 'dropout_prb_l2': 0.8, 'num_l3': 6, 'dropout_prb_l3': 0.2, 'epochs': 500, 'optimizer': 'NAdam', 'learning_rate': 0.00022741598023524697}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5737871674491394\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:26:25,938] Trial 37 finished with value: 0.17009289781240639 and parameters: {'Number of layers': 3, 'num_l0': 7, 'dropout_prb_l0': 0.2, 'num_l1': 8, 'dropout_prb_l1': 1.0, 'num_l2': 9, 'dropout_prb_l2': 0.6000000000000001, 'epochs': 600, 'optimizer': 'RMSprop', 'learning_rate': 0.0018606460060094988}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.17009289781240639\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:26:42,120] Trial 38 finished with value: 0.5137232377717844 and parameters: {'Number of layers': 4, 'num_l0': 5, 'dropout_prb_l0': 0.6000000000000001, 'num_l1': 7, 'dropout_prb_l1': 0.8, 'num_l2': 7, 'dropout_prb_l2': 0.2, 'num_l3': 9, 'dropout_prb_l3': 0.6000000000000001, 'epochs': 800, 'optimizer': 'NAdam', 'learning_rate': 0.00015191706842606495}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5137232377717844\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:26:53,859] Trial 39 finished with value: 0.4789581460393567 and parameters: {'Number of layers': 5, 'num_l0': 7, 'dropout_prb_l0': 0.4, 'num_l1': 9, 'dropout_prb_l1': 0.4, 'num_l2': 8, 'dropout_prb_l2': 0.4, 'num_l3': 8, 'dropout_prb_l3': 0.8, 'num_l4': 7, 'dropout_prb_l4': 0.4, 'epochs': 600, 'optimizer': 'SGD', 'learning_rate': 0.007998398800039132}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.4789581460393567\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:27:02,301] Trial 40 finished with value: 0.17845869543502146 and parameters: {'Number of layers': 3, 'num_l0': 6, 'dropout_prb_l0': 0.8, 'num_l1': 6, 'dropout_prb_l1': 1.0, 'num_l2': 6, 'dropout_prb_l2': 0.8, 'epochs': 500, 'optimizer': 'NAdam', 'learning_rate': 0.0004258534568255654}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.17845869543502146\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:27:16,345] Trial 41 finished with value: 0.59383178503646 and parameters: {'Number of layers': 4, 'num_l0': 5, 'dropout_prb_l0': 0.2, 'num_l1': 8, 'dropout_prb_l1': 0.8, 'num_l2': 9, 'dropout_prb_l2': 0.4, 'num_l3': 9, 'dropout_prb_l3': 0.6000000000000001, 'epochs': 700, 'optimizer': 'NAdam', 'learning_rate': 0.0006370218896064789}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.59383178503646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:27:30,651] Trial 42 finished with value: 0.5818383111910232 and parameters: {'Number of layers': 4, 'num_l0': 6, 'dropout_prb_l0': 0.2, 'num_l1': 8, 'dropout_prb_l1': 0.8, 'num_l2': 9, 'dropout_prb_l2': 0.4, 'num_l3': 9, 'dropout_prb_l3': 0.6000000000000001, 'epochs': 700, 'optimizer': 'NAdam', 'learning_rate': 0.0007711391276970358}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5818383111910232\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:27:44,268] Trial 43 finished with value: 0.5959877468118403 and parameters: {'Number of layers': 4, 'num_l0': 5, 'dropout_prb_l0': 0.2, 'num_l1': 9, 'dropout_prb_l1': 0.6000000000000001, 'num_l2': 9, 'dropout_prb_l2': 0.6000000000000001, 'num_l3': 9, 'dropout_prb_l3': 0.6000000000000001, 'epochs': 700, 'optimizer': 'Adam', 'learning_rate': 0.00020958198210793295}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5959877468118403\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:27:59,740] Trial 44 finished with value: 0.5434139113641661 and parameters: {'Number of layers': 4, 'num_l0': 6, 'dropout_prb_l0': 0.4, 'num_l1': 9, 'dropout_prb_l1': 0.6000000000000001, 'num_l2': 4, 'dropout_prb_l2': 0.6000000000000001, 'num_l3': 8, 'dropout_prb_l3': 0.4, 'epochs': 800, 'optimizer': 'Adam', 'learning_rate': 0.00020464878769166977}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5434139113641661\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:28:13,650] Trial 45 finished with value: 0.20321812672726666 and parameters: {'Number of layers': 4, 'num_l0': 5, 'dropout_prb_l0': 0.0, 'num_l1': 9, 'dropout_prb_l1': 0.6000000000000001, 'num_l2': 9, 'dropout_prb_l2': 1.0, 'num_l3': 9, 'dropout_prb_l3': 0.8, 'epochs': 700, 'optimizer': 'Adam', 'learning_rate': 0.00011066569339473483}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.20321812672726666\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:28:26,331] Trial 46 finished with value: 0.5532564179402657 and parameters: {'Number of layers': 3, 'num_l0': 4, 'dropout_prb_l0': 0.2, 'num_l1': 9, 'dropout_prb_l1': 0.4, 'num_l2': 8, 'dropout_prb_l2': 0.6000000000000001, 'epochs': 800, 'optimizer': 'Adam', 'learning_rate': 0.0003651967799900376}. Best is trial 26 with value: 0.6103502813571737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5532564179402657\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:28:37,531] Trial 47 finished with value: 0.620017980221756 and parameters: {'Number of layers': 2, 'num_l0': 5, 'dropout_prb_l0': 0.0, 'num_l1': 9, 'dropout_prb_l1': 0.6000000000000001, 'epochs': 600, 'optimizer': 'Adamax', 'learning_rate': 0.00021501608010871881}. Best is trial 47 with value: 0.620017980221756.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.620017980221756\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:28:48,093] Trial 48 finished with value: 0.5850913994605933 and parameters: {'Number of layers': 2, 'num_l0': 9, 'dropout_prb_l0': 0.0, 'num_l1': 8, 'dropout_prb_l1': 0.8, 'epochs': 600, 'optimizer': 'Adamax', 'learning_rate': 0.0010931163796601788}. Best is trial 47 with value: 0.620017980221756.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.5850913994605933\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-15 20:28:59,302] Trial 49 finished with value: 0.6315536243465523 and parameters: {'Number of layers': 2, 'num_l0': 6, 'dropout_prb_l0': 0.0, 'num_l1': 7, 'dropout_prb_l1': 0.6000000000000001, 'epochs': 600, 'optimizer': 'Adamax', 'learning_rate': 0.0002809164323468978}. Best is trial 49 with value: 0.6315536243465523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "5-fold Validation MAPK: 0.6315536243465523\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_function, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Getting best `map@k` and best model paramters during the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAPK while optimizing: 0.6315536243465523\n"
     ]
    }
   ],
   "source": [
    "print(f'Best MAPK while optimizing: {study.best_trial.value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 2\n",
      "num_l0: 6\n",
      "dropout_prb_l0: 0.0\n",
      "num_l1: 7\n",
      "dropout_prb_l1: 0.6000000000000001\n",
      "epochs: 600\n",
      "optimizer: Adamax\n",
      "learning_rate: 0.0002809164323468978\n"
     ]
    }
   ],
   "source": [
    "for key, value in study.best_trial.params.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "## 4. Cross validation evaluation of tuned neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Creating the network\n",
    "\n",
    "A new neural network with the tuned parameters is then created (from scratch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mcClassifier(nn.Module):\n",
    "# feedforward MLP with batch-norm\n",
    "    def __init__ (self, num_input, num_output=11):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # tuned number of layers\n",
    "        self.linear_layer_nn = nn.Sequential(\n",
    "\n",
    "            # layer 1 with tuned parameters\n",
    "            nn.Linear(in_features = num_input, out_features = 2**6),\n",
    "            nn.BatchNorm1d(2**6),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.),\n",
    "\n",
    "            # layer 2 with tuned parameters\n",
    "            nn.Linear(2**6, 2**7),\n",
    "            nn.BatchNorm1d(2**7),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.6),\n",
    "\n",
    "            # nn.Linear(2**7, 2**7),\n",
    "            # nn.BatchNorm1d(2**7),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(p=0.8),\n",
    "\n",
    "            # nn.Linear(2**7, 2**7),\n",
    "            # nn.BatchNorm1d(2**7),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(p=0.8),\n",
    "\n",
    "            nn.Linear(2**7, num_output)\n",
    "        )\n",
    "\n",
    "    def forward (self, x):\n",
    "        return self.linear_layer_nn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### 10-fold evaluation\n",
    "\n",
    "The created netwrok is then trained and evaulated to obtain the `10-fold map@k` score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Epoch: 0\n",
      "Train Loss: 2.570833206176758\n",
      "Train MAPK: 0.14229559748427673\n",
      "\n",
      "Epoch: 100\n",
      "Train Loss: 1.6676687002182007\n",
      "Train MAPK: 0.5110062893081762\n",
      "\n",
      "Epoch: 200\n",
      "Train Loss: 1.3928552865982056\n",
      "Train MAPK: 0.5990566037735849\n",
      "\n",
      "Epoch: 300\n",
      "Train Loss: 1.2039768695831299\n",
      "Train MAPK: 0.6462264150943396\n",
      "\n",
      "Epoch: 400\n",
      "Train Loss: 1.1414815187454224\n",
      "Train MAPK: 0.6582809224318658\n",
      "\n",
      "Epoch: 500\n",
      "Train Loss: 1.0797597169876099\n",
      "Train MAPK: 0.6629979035639413\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "Test MAPK: 0.563380281690141\n",
      "\n",
      "\n",
      "Fold 1:\n",
      "Epoch: 0\n",
      "Train Loss: 2.545707941055298\n",
      "Train MAPK: 0.1441299790356394\n",
      "\n",
      "Epoch: 100\n",
      "Train Loss: 1.7216054201126099\n",
      "Train MAPK: 0.5013102725366877\n",
      "\n",
      "Epoch: 200\n",
      "Train Loss: 1.43229341506958\n",
      "Train MAPK: 0.5893605870020964\n",
      "\n",
      "Epoch: 300\n",
      "Train Loss: 1.3051470518112183\n",
      "Train MAPK: 0.6247379454926625\n",
      "\n",
      "Epoch: 400\n",
      "Train Loss: 1.1545343399047852\n",
      "Train MAPK: 0.6488469601677148\n",
      "\n",
      "Epoch: 500\n",
      "Train Loss: 1.0993974208831787\n",
      "Train MAPK: 0.6750524109014675\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "Test MAPK: 0.6713615023474178\n",
      "\n",
      "\n",
      "Fold 2:\n",
      "Epoch: 0\n",
      "Train Loss: 2.659259796142578\n",
      "Train MAPK: 0.10796645702306078\n",
      "\n",
      "Epoch: 100\n",
      "Train Loss: 1.7959978580474854\n",
      "Train MAPK: 0.4769392033542977\n",
      "\n",
      "Epoch: 200\n",
      "Train Loss: 1.4610860347747803\n",
      "Train MAPK: 0.590146750524109\n",
      "\n",
      "Epoch: 300\n",
      "Train Loss: 1.319607138633728\n",
      "Train MAPK: 0.629454926624738\n",
      "\n",
      "Epoch: 400\n",
      "Train Loss: 1.187922716140747\n",
      "Train MAPK: 0.640461215932914\n",
      "\n",
      "Epoch: 500\n",
      "Train Loss: 1.1392134428024292\n",
      "Train MAPK: 0.6645702306079664\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "Test MAPK: 0.6572769953051644\n",
      "\n",
      "\n",
      "Fold 3:\n",
      "Epoch: 0\n",
      "Train Loss: 2.6729485988616943\n",
      "Train MAPK: 0.13233752620545072\n",
      "\n",
      "Epoch: 100\n",
      "Train Loss: 1.7638533115386963\n",
      "Train MAPK: 0.4903039832285116\n",
      "\n",
      "Epoch: 200\n",
      "Train Loss: 1.408915638923645\n",
      "Train MAPK: 0.6142557651991614\n",
      "\n",
      "Epoch: 300\n",
      "Train Loss: 1.270511507987976\n",
      "Train MAPK: 0.6365303983228511\n",
      "\n",
      "Epoch: 400\n",
      "Train Loss: 1.160543441772461\n",
      "Train MAPK: 0.6669287211740041\n",
      "\n",
      "Epoch: 500\n",
      "Train Loss: 1.0706008672714233\n",
      "Train MAPK: 0.6732180293501049\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "Test MAPK: 0.5938967136150234\n",
      "\n",
      "\n",
      "Fold 4:\n",
      "Epoch: 0\n",
      "Train Loss: 2.6083595752716064\n",
      "Train MAPK: 0.125\n",
      "\n",
      "Epoch: 100\n",
      "Train Loss: 1.7451826333999634\n",
      "Train MAPK: 0.49580712788259956\n",
      "\n",
      "Epoch: 200\n",
      "Train Loss: 1.4046329259872437\n",
      "Train MAPK: 0.600104821802935\n",
      "\n",
      "Epoch: 300\n",
      "Train Loss: 1.2820696830749512\n",
      "Train MAPK: 0.6210691823899371\n",
      "\n",
      "Epoch: 400\n",
      "Train Loss: 1.2049294710159302\n",
      "Train MAPK: 0.6386268343815513\n",
      "\n",
      "Epoch: 500\n",
      "Train Loss: 1.1379796266555786\n",
      "Train MAPK: 0.6491090146750523\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "Test MAPK: 0.687793427230047\n",
      "\n",
      "\n",
      "Fold 5:\n",
      "Epoch: 0\n",
      "Train Loss: 2.583329677581787\n",
      "Train MAPK: 0.16430817610062892\n",
      "\n",
      "Epoch: 100\n",
      "Train Loss: 1.7398585081100464\n",
      "Train MAPK: 0.49109014675052415\n",
      "\n",
      "Epoch: 200\n",
      "Train Loss: 1.458095669746399\n",
      "Train MAPK: 0.5893605870020965\n",
      "\n",
      "Epoch: 300\n",
      "Train Loss: 1.2945505380630493\n",
      "Train MAPK: 0.6302410901467504\n",
      "\n",
      "Epoch: 400\n",
      "Train Loss: 1.1544055938720703\n",
      "Train MAPK: 0.659853249475891\n",
      "\n",
      "Epoch: 500\n",
      "Train Loss: 1.1000396013259888\n",
      "Train MAPK: 0.6734800838574424\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "Test MAPK: 0.6384976525821596\n",
      "\n",
      "\n",
      "Fold 6:\n",
      "Epoch: 0\n",
      "Train Loss: 2.573763608932495\n",
      "Train MAPK: 0.16378406708595386\n",
      "\n",
      "Epoch: 100\n",
      "Train Loss: 1.6870607137680054\n",
      "Train MAPK: 0.5039308176100629\n",
      "\n",
      "Epoch: 200\n",
      "Train Loss: 1.4119236469268799\n",
      "Train MAPK: 0.5990566037735849\n",
      "\n",
      "Epoch: 300\n",
      "Train Loss: 1.2491421699523926\n",
      "Train MAPK: 0.640461215932914\n",
      "\n",
      "Epoch: 400\n",
      "Train Loss: 1.2033865451812744\n",
      "Train MAPK: 0.64937106918239\n",
      "\n",
      "Epoch: 500\n",
      "Train Loss: 1.1044217348098755\n",
      "Train MAPK: 0.6763626834381552\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "Test MAPK: 0.6173708920187793\n",
      "\n",
      "\n",
      "Fold 7:\n",
      "Epoch: 0\n",
      "Train Loss: 2.5141565799713135\n",
      "Train MAPK: 0.17870225013082155\n",
      "\n",
      "Epoch: 100\n",
      "Train Loss: 1.656899094581604\n",
      "Train MAPK: 0.5303506017791733\n",
      "\n",
      "Epoch: 200\n",
      "Train Loss: 1.3899906873703003\n",
      "Train MAPK: 0.608058608058608\n",
      "\n",
      "Epoch: 300\n",
      "Train Loss: 1.2294961214065552\n",
      "Train MAPK: 0.6473050758765044\n",
      "\n",
      "Epoch: 400\n",
      "Train Loss: 1.111452341079712\n",
      "Train MAPK: 0.6802721088435375\n",
      "\n",
      "Epoch: 500\n",
      "Train Loss: 1.0911579132080078\n",
      "Train MAPK: 0.6755625327053899\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "Test MAPK: 0.5285714285714286\n",
      "\n",
      "\n",
      "Fold 8:\n",
      "Epoch: 0\n",
      "Train Loss: 2.527768135070801\n",
      "Train MAPK: 0.1682365253793825\n",
      "\n",
      "Epoch: 100\n",
      "Train Loss: 1.6462092399597168\n",
      "Train MAPK: 0.5450026164311877\n",
      "\n",
      "Epoch: 200\n",
      "Train Loss: 1.3782639503479004\n",
      "Train MAPK: 0.6057038199895343\n",
      "\n",
      "Epoch: 300\n",
      "Train Loss: 1.255308985710144\n",
      "Train MAPK: 0.6378859236002093\n",
      "\n",
      "Epoch: 400\n",
      "Train Loss: 1.1736059188842773\n",
      "Train MAPK: 0.6643118785975928\n",
      "\n",
      "Epoch: 500\n",
      "Train Loss: 1.1025142669677734\n",
      "Train MAPK: 0.67425431711146\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "Test MAPK: 0.6857142857142857\n",
      "\n",
      "\n",
      "Fold 9:\n",
      "Epoch: 0\n",
      "Train Loss: 2.5761260986328125\n",
      "Train MAPK: 0.17791732077446362\n",
      "\n",
      "Epoch: 100\n",
      "Train Loss: 1.6698322296142578\n",
      "Train MAPK: 0.5274725274725275\n",
      "\n",
      "Epoch: 200\n",
      "Train Loss: 1.4137279987335205\n",
      "Train MAPK: 0.6240188383045526\n",
      "\n",
      "Epoch: 300\n",
      "Train Loss: 1.2448455095291138\n",
      "Train MAPK: 0.6384092098377813\n",
      "\n",
      "Epoch: 400\n",
      "Train Loss: 1.1694029569625854\n",
      "Train MAPK: 0.6593406593406593\n",
      "\n",
      "Epoch: 500\n",
      "Train Loss: 1.0683424472808838\n",
      "Train MAPK: 0.6881214024071166\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "Test MAPK: 0.6119047619047618\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      "10-fold Validation MAPK: 0.6255767940979208\n"
     ]
    }
   ],
   "source": [
    "# tuned number of epochs\n",
    "epochs = 600\n",
    "\n",
    "# 10-fold CV\n",
    "k = 10\n",
    "skf = StratifiedKFold(n_splits=k)\n",
    "\n",
    "mapk_list = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "\n",
    "    # resetting model weights\n",
    "    mcModel = mcClassifier(num_input=n_features, num_output=11).to(device)\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # tuned optimizer and learning rate\n",
    "    optimizer = torch.optim.Adamax(params=mcModel.parameters(), lr=0.0002809164323468978)\n",
    "    \n",
    "    print(f\"Fold {i}:\")\n",
    "    \n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "    X_train_tensor = torch.from_numpy(X_train.values).type(torch.float).to(device)\n",
    "    y_train_tensor = torch.from_numpy(y_train.values).type(torch.LongTensor).to(device)\n",
    "\n",
    "    X_test_tensor = torch.from_numpy(X_test.values).type(torch.float).to(device)\n",
    "    y_test_tensor = torch.from_numpy(y_test.values).type(torch.LongTensor).to(device)\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # enter training mode\n",
    "        mcModel.train()\n",
    "\n",
    "        y_train_logits = mcModel(X_train_tensor)\n",
    "        y_train_pred_probs = torch.softmax(y_train_logits, dim=1)\n",
    "\n",
    "        loss = loss_function(y_train_logits, y_train_tensor)\n",
    "\n",
    "        mapk = mapk_score(y_train, y_train_pred_probs.cpu().detach().numpy())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch: {epoch}\\nTrain Loss: {loss}\\nTrain MAPK: {mapk}\\n')\n",
    "\n",
    "\n",
    "    # enter testing mode\n",
    "    mcModel.eval()\n",
    "    \n",
    "    y_test_logits = mcModel(X_test_tensor).to(device)\n",
    "\n",
    "    y_test_pred_probs = torch.softmax(y_test_logits, dim=1)\n",
    "    y_test_pred_probs = y_test_pred_probs.cpu()\n",
    "    y_test_pred_probs = y_test_pred_probs.detach().numpy()\n",
    "    \n",
    "    print(f'\\n---------------------------------------------\\nTest MAPK: {mapk_score(y_test, y_test_pred_probs)}\\n\\n')\n",
    "\n",
    "    mapk_list.append(mapk_score(y_test, y_test_pred_probs))\n",
    "\n",
    "\n",
    "print(f'\\n---------------------------------------------\\n{k}-fold Validation MAPK: {np.average(mapk_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## 5. Generating Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv('./data/Kaggle/test.csv')\n",
    "# col_id = test_df['id']\n",
    "\n",
    "# test_df = test_df.astype(int)\n",
    "# test_df = combine_features(test_df)\n",
    "# test_df = cluster_features(test_df)\n",
    "# test_df = affinity_propagation_features(test_df)\n",
    "# test_df = test_df[rfe_selector.get_feature_names_out()]\n",
    "\n",
    "# # n_features = test_df.shape[1] - 1\n",
    "# # test_df.columns = [f\"x{i}\" for i in range(1, n_features+2)]\n",
    "\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = mcClassifier(num_input=n_features, num_output=11).to(device)\n",
    "\n",
    "# test_tensor = torch.from_numpy(test_df.values).type(torch.float).to(device)\n",
    "\n",
    "# test_model.eval()\n",
    "# y_test_logits = test_model(test_tensor).to(device)\n",
    "\n",
    "# y_test_pred_probs = torch.softmax(y_test_logits, dim=1)\n",
    "# y_test_pred_probs = y_test_pred_probs.cpu()\n",
    "# y_test_pred_probs = y_test_pred_probs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sorted_prediction_ids = np.argsort(-y_test_pred_probs, axis=1)\n",
    "# test_top_3_prediction_ids = test_sorted_prediction_ids[:,:3]\n",
    "# original_shape = test_top_3_prediction_ids.shape\n",
    "# test_top_3_prediction = enc.inverse_transform(test_top_3_prediction_ids.reshape(-1, 1))\n",
    "# test_top_3_prediction = test_top_3_prediction.reshape(original_shape)\n",
    "\n",
    "# test_df['prognosis'] = np.apply_along_axis(lambda x: np.array(' '.join(x), dtype=\"object\"), 1, test_top_3_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame()\n",
    "\n",
    "# submission['id'] = col_id\n",
    "# submission['prognosis'] = test_df['prognosis']\n",
    "\n",
    "# submission.to_csv('./data/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
