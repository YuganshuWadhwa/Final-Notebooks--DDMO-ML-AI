{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RANDOM FOREST CLASSIFICATION <br>WITH HYPERPARAMETER TUNING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "**Random Forest Classification** is a supervised machine learning algorithm. \n",
    "\n",
    "**Supervised Learning** is a subclass of machine learning that uses *labeled data* to learn and search for patterns in the input data that correlate with the correct output label. \n",
    "\n",
    "The objective of a **classification algorithm** is to assign input data to a specific class or label. \n",
    "\n",
    "Real life applications are spam detection, or predictive analysis to help predict a certain outcome (e.g. disease diagnosis). \n",
    "\n",
    "<sup><sub>Sources: [towardsdatascience](https://towardsdatascience.com/a-brief-introduction-to-supervised-learning-54a3e3932590), [IBM](https://www.ibm.com/topics/supervised-learning)</sub></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## How does Random Forest Work ?\n",
    "\n",
    "To explain how the ***Random Forest Classification (RFC)*** algorithm works we need to first explain how ***decision trees*** work as this is the basis of RFC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Decision Trees\n",
    "\n",
    "A decision tree consists of `nodes` and `branches`. In the simplest form, ***each node has a condition*** that splits the data into branches. The ***goal is to get a leaf node*** or pure node where only one class of the data is present.\n",
    "\n",
    "Choosing a condition to split the data is not always trivial though. This is why the model tries to maximise the ***information gain*** for each node. To evaluate the information-gain one can calculate the ***Entropy*** or Gini index.\n",
    "\n",
    "<br>\n",
    "\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:720/format:webp/1*3P1333UmqEww6YMpjisj4Q.png \"Decision Tree Structure\")\n",
    "\n",
    "<sup><sub>Source: [medium.com](https://towardsdatascience.com/decision-trees-explained-3ec41632ceb6)</sub></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Random Forest Classification\n",
    "\n",
    "As the name now suggests, ***Random Forest Classification consist of many individual trees*** that work together to get a less a biased prediction. To determine a class the algorithm uses ***majority voting***. Each tree makes predictions for a given instance, and the final result is determined by selecting the class with the highest number of votes among the trees.\n",
    "\n",
    "<br>\n",
    "\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:640/format:webp/1*VHDtVaDPNepRglIAv72BFg.jpeg  \"Majority Voting\")\n",
    "\n",
    "<sup><sub>Source: [towardsdatascience](https://towardsdatascience.com/understanding-random-forest-58381e0602d2 )</sub></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "##### **Tackling over-fitting**\n",
    "Using many trees reduces the influence of the error of each tree. This tackles the issue of the Decision Tree algorithm which tends to overfit on the training data.\n",
    "<br>\n",
    "\n",
    "##### **Bagging**\n",
    "To further reduce the sensitivity to the training data, we employ a technique known as ***bootstrapping***. This approach involves taking the initial dataset and generating multiple simulated datasets by resampling (with replacement) from it. Each tree is then constructed using one of these newly generated and sampled datasets. ***Combining bootstrapping with the aggregation*** of individual predictions is also known as ***bagging***.\n",
    "<br>\n",
    "\n",
    "##### **Random Features**\n",
    "Trees exhibiting strong correlation tend to behave similarly, which can lead to similar errors. ***Random feature selection*** helps maintain the diversity and effectiveness of the tree ensemble, by taking only a certain number of random features from the bootstrapped data sets instead of using all of them. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MAX_TIME` determines the maximum amount of time the optimiser runs for after creating the initial models. \n",
    "\n",
    "`INIT_SIZE` controls how many initial models will be evaluated before building a surrogate and optimising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME = 10 # Time in minutes. Counter starts, after the initial design is evaluated. So, runtime can be larger.\n",
    "INIT_SIZE = 50 # Initial number of designs to evaluate, before the surrogate is build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16-sklearnRandomForestClassifier_nomad_10min_50init_2023-07-15_19-52-38\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "start_time = datetime.now(tzlocal())\n",
    "HOSTNAME = socket.gethostname().split(\".\")[0]\n",
    "experiment_name = '16-sklearnRandomForestClassifier' + \"_\" + HOSTNAME + \"_\" + str(MAX_TIME) + \"min_\" + str(INIT_SIZE) + \"init_\" + str(start_time).split(\".\", 1)[0].replace(' ', '_')\n",
    "experiment_name = experiment_name.replace(':', '-')\n",
    "print(experiment_name)\n",
    "if not os.path.exists('./figures'):\n",
    "    os.makedirs('./figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'grep' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep  \"spot[RiverPython]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import warnings\n",
    "import numpy as np\n",
    "from math import inf\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder , MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline , Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, roc_curve, roc_auc_score, log_loss, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from spotPython.spot import spot\n",
    "from spotPython.hyperparameters.values import (\n",
    "    add_core_model_to_fun_control,\n",
    "    assign_values,\n",
    "    convert_keys,\n",
    "    get_bound_values,\n",
    "    get_default_hyperparameters_for_core_model,\n",
    "    get_default_values,\n",
    "    get_default_hyperparameters_as_array,\n",
    "    get_dict_with_levels_and_types,\n",
    "    get_values_from_dict,\n",
    "    get_var_name,\n",
    "    get_var_type,\n",
    "    iterate_dict_values,\n",
    "    modify_hyper_parameter_levels,\n",
    "    modify_hyper_parameter_bounds,\n",
    "    replace_levels_with_positions,\n",
    "    return_conf_list_from_var_dict,\n",
    "    get_one_core_model_from_X,\n",
    "    transform_hyper_parameter_values,\n",
    "    get_dict_with_levels_and_types,\n",
    "    convert_keys,\n",
    "    iterate_dict_values,\n",
    "    get_one_sklearn_model_from_X\n",
    ")\n",
    "\n",
    "from spotPython.utils.convert import class_for_name\n",
    "from spotPython.utils.eda import (\n",
    "    get_stars,\n",
    "    gen_design_table)\n",
    "from spotPython.utils.transform import transform_hyper_parameter_values\n",
    "from spotPython.utils.convert import get_Xy_from_df\n",
    "from spotPython.plot.validation import plot_cv_predictions, plot_roc, plot_confusion_matrix\n",
    "from spotPython.utils.init import fun_control_init\n",
    "\n",
    "from spotPython.data.sklearn_hyper_dict import SklearnHyperDict\n",
    "from spotPython.fun.hypersklearn import HyperSklearn\n",
    "from spotPython.utils.metrics import mapk_score\n",
    "\n",
    "import itertools\n",
    "import joblib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## 1. Loading Dataset: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector Borne Disease Prediction Data\n",
    "\n",
    "The **Vector Borne Disease Dataset** was used in a study to predict medical prognosis. It consisted of hundreds of samples with case-specific features. The dataset included a target variable `prognosis` representing prognostic outcomes divided into **eleven classes**. To prepare the dataset for training a classifier model, preprocessing steps involved encoding prognosis names and performing feature engineering. **The goal was to predict the prognosis for unknown data based on the trained model.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>breathing_restriction</th>\n",
       "      <th>toe_inflammation</th>\n",
       "      <th>finger_inflammation</th>\n",
       "      <th>lips_irritation</th>\n",
       "      <th>itchiness</th>\n",
       "      <th>ulcers</th>\n",
       "      <th>toenail_loss</th>\n",
       "      <th>speech_problem</th>\n",
       "      <th>bullseye_rash</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lyme_disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tungiasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lyme_disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rift_Valley_fever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Plague</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Malaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Plague</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tungiasis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain   \n",
       "0             1.0       1.0          0.0         1.0          1.0         1.0  \\\n",
       "1             0.0       0.0          0.0         0.0          0.0         0.0   \n",
       "2             0.0       1.0          1.0         1.0          0.0         1.0   \n",
       "3             0.0       0.0          1.0         1.0          1.0         1.0   \n",
       "4             0.0       0.0          0.0         0.0          0.0         0.0   \n",
       "..            ...       ...          ...         ...          ...         ...   \n",
       "702           0.0       0.0          1.0         1.0          1.0         0.0   \n",
       "703           1.0       0.0          1.0         1.0          1.0         1.0   \n",
       "704           1.0       0.0          1.0         0.0          1.0         0.0   \n",
       "705           1.0       1.0          0.0         0.0          1.0         0.0   \n",
       "706           1.0       1.0          0.0         0.0          0.0         0.0   \n",
       "\n",
       "     vomiting  rash  diarrhea  hypotension  ...  breathing_restriction   \n",
       "0         1.0   0.0       1.0          1.0  ...                    0.0  \\\n",
       "1         1.0   0.0       1.0          0.0  ...                    0.0   \n",
       "2         1.0   1.0       1.0          1.0  ...                    1.0   \n",
       "3         0.0   1.0       0.0          1.0  ...                    0.0   \n",
       "4         0.0   0.0       1.0          0.0  ...                    0.0   \n",
       "..        ...   ...       ...          ...  ...                    ...   \n",
       "702       0.0   0.0       0.0          0.0  ...                    0.0   \n",
       "703       0.0   1.0       1.0          0.0  ...                    0.0   \n",
       "704       0.0   1.0       1.0          1.0  ...                    0.0   \n",
       "705       1.0   0.0       1.0          0.0  ...                    1.0   \n",
       "706       1.0   0.0       0.0          0.0  ...                    0.0   \n",
       "\n",
       "     toe_inflammation  finger_inflammation  lips_irritation  itchiness   \n",
       "0                 0.0                  0.0              0.0        0.0  \\\n",
       "1                 0.0                  0.0              0.0        0.0   \n",
       "2                 1.0                  1.0              1.0        1.0   \n",
       "3                 0.0                  0.0              0.0        0.0   \n",
       "4                 1.0                  0.0              0.0        1.0   \n",
       "..                ...                  ...              ...        ...   \n",
       "702               0.0                  0.0              0.0        0.0   \n",
       "703               0.0                  0.0              0.0        0.0   \n",
       "704               0.0                  0.0              0.0        0.0   \n",
       "705               1.0                  1.0              1.0        0.0   \n",
       "706               0.0                  0.0              0.0        1.0   \n",
       "\n",
       "     ulcers  toenail_loss  speech_problem  bullseye_rash          prognosis  \n",
       "0       0.0           0.0             0.0            0.0       Lyme_disease  \n",
       "1       0.0           0.0             0.0            0.0          Tungiasis  \n",
       "2       0.0           1.0             1.0            1.0       Lyme_disease  \n",
       "3       0.0           0.0             0.0            0.0               Zika  \n",
       "4       1.0           1.0             0.0            0.0  Rift_Valley_fever  \n",
       "..      ...           ...             ...            ...                ...  \n",
       "702     0.0           0.0             0.0            0.0             Plague  \n",
       "703     0.0           0.0             0.0            0.0            Malaria  \n",
       "704     0.0           0.0             0.0            0.0               Zika  \n",
       "705     0.0           0.0             0.0            0.0             Plague  \n",
       "706     1.0           1.0             0.0            0.0          Tungiasis  \n",
       "\n",
       "[707 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/Kaggle/train.csv')\n",
    "\n",
    "# remove the id column\n",
    "train_df = train_df.drop(columns=['id'])\n",
    "\n",
    "global target_column\n",
    "target_column = \"prognosis\"\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "## 2. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### `Encoding`\n",
    "\n",
    "Encoding is a way of transforming categorical variables into a numerical format since the algorithm cannot work with categorical variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>breathing_restriction</th>\n",
       "      <th>toe_inflammation</th>\n",
       "      <th>finger_inflammation</th>\n",
       "      <th>lips_irritation</th>\n",
       "      <th>itchiness</th>\n",
       "      <th>ulcers</th>\n",
       "      <th>toenail_loss</th>\n",
       "      <th>speech_problem</th>\n",
       "      <th>bullseye_rash</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain   \n",
       "0             1.0       1.0          0.0         1.0          1.0         1.0  \\\n",
       "1             0.0       0.0          0.0         0.0          0.0         0.0   \n",
       "2             0.0       1.0          1.0         1.0          0.0         1.0   \n",
       "3             0.0       0.0          1.0         1.0          1.0         1.0   \n",
       "4             0.0       0.0          0.0         0.0          0.0         0.0   \n",
       "..            ...       ...          ...         ...          ...         ...   \n",
       "702           0.0       0.0          1.0         1.0          1.0         0.0   \n",
       "703           1.0       0.0          1.0         1.0          1.0         1.0   \n",
       "704           1.0       0.0          1.0         0.0          1.0         0.0   \n",
       "705           1.0       1.0          0.0         0.0          1.0         0.0   \n",
       "706           1.0       1.0          0.0         0.0          0.0         0.0   \n",
       "\n",
       "     vomiting  rash  diarrhea  hypotension  ...  breathing_restriction   \n",
       "0         1.0   0.0       1.0          1.0  ...                    0.0  \\\n",
       "1         1.0   0.0       1.0          0.0  ...                    0.0   \n",
       "2         1.0   1.0       1.0          1.0  ...                    1.0   \n",
       "3         0.0   1.0       0.0          1.0  ...                    0.0   \n",
       "4         0.0   0.0       1.0          0.0  ...                    0.0   \n",
       "..        ...   ...       ...          ...  ...                    ...   \n",
       "702       0.0   0.0       0.0          0.0  ...                    0.0   \n",
       "703       0.0   1.0       1.0          0.0  ...                    0.0   \n",
       "704       0.0   1.0       1.0          1.0  ...                    0.0   \n",
       "705       1.0   0.0       1.0          0.0  ...                    1.0   \n",
       "706       1.0   0.0       0.0          0.0  ...                    0.0   \n",
       "\n",
       "     toe_inflammation  finger_inflammation  lips_irritation  itchiness   \n",
       "0                 0.0                  0.0              0.0        0.0  \\\n",
       "1                 0.0                  0.0              0.0        0.0   \n",
       "2                 1.0                  1.0              1.0        1.0   \n",
       "3                 0.0                  0.0              0.0        0.0   \n",
       "4                 1.0                  0.0              0.0        1.0   \n",
       "..                ...                  ...              ...        ...   \n",
       "702               0.0                  0.0              0.0        0.0   \n",
       "703               0.0                  0.0              0.0        0.0   \n",
       "704               0.0                  0.0              0.0        0.0   \n",
       "705               1.0                  1.0              1.0        0.0   \n",
       "706               0.0                  0.0              0.0        1.0   \n",
       "\n",
       "     ulcers  toenail_loss  speech_problem  bullseye_rash  prognosis  \n",
       "0       0.0           0.0             0.0            0.0        3.0  \n",
       "1       0.0           0.0             0.0            0.0        7.0  \n",
       "2       0.0           1.0             1.0            1.0        3.0  \n",
       "3       0.0           0.0             0.0            0.0       10.0  \n",
       "4       1.0           1.0             0.0            0.0        6.0  \n",
       "..      ...           ...             ...            ...        ...  \n",
       "702     0.0           0.0             0.0            0.0        5.0  \n",
       "703     0.0           0.0             0.0            0.0        4.0  \n",
       "704     0.0           0.0             0.0            0.0       10.0  \n",
       "705     0.0           0.0             0.0            0.0        5.0  \n",
       "706     1.0           1.0             0.0            0.0        7.0  \n",
       "\n",
       "[707 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OrdinalEncoder()\n",
    "train_df[target_column] = enc.fit_transform(train_df[[target_column]])\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### `Feature Combination`\n",
    "\n",
    "This is performed to create new features by combining existing features in a dataset using some logic. This process aims to add additional information that may not be evident in the original features alone. In our case this is achieved by applying the boolean operators `and`, `or` and `xor` on the initial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(df):\n",
    "\n",
    "    for col1, col2 in itertools.combinations(df.columns,2):\n",
    "        df[f'{col1}_and_{col2}'] = df[col1] & df[col2]\n",
    "        df[f'{col1}_or_{col2}'] = df[col1] | df[col2]\n",
    "        df[f'{col1}_xor_{col2}'] = df[col1] ^ df[col2]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>toenail_loss_and_speech_problem</th>\n",
       "      <th>toenail_loss_or_speech_problem</th>\n",
       "      <th>toenail_loss_xor_speech_problem</th>\n",
       "      <th>toenail_loss_and_bullseye_rash</th>\n",
       "      <th>toenail_loss_or_bullseye_rash</th>\n",
       "      <th>toenail_loss_xor_bullseye_rash</th>\n",
       "      <th>speech_problem_and_bullseye_rash</th>\n",
       "      <th>speech_problem_or_bullseye_rash</th>\n",
       "      <th>speech_problem_xor_bullseye_rash</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 6113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain   \n",
       "0               1         1            0           1            1           1  \\\n",
       "1               0         0            0           0            0           0   \n",
       "2               0         1            1           1            0           1   \n",
       "3               0         0            1           1            1           1   \n",
       "4               0         0            0           0            0           0   \n",
       "..            ...       ...          ...         ...          ...         ...   \n",
       "702             0         0            1           1            1           0   \n",
       "703             1         0            1           1            1           1   \n",
       "704             1         0            1           0            1           0   \n",
       "705             1         1            0           0            1           0   \n",
       "706             1         1            0           0            0           0   \n",
       "\n",
       "     vomiting  rash  diarrhea  hypotension  ...   \n",
       "0           1     0         1            1  ...  \\\n",
       "1           1     0         1            0  ...   \n",
       "2           1     1         1            1  ...   \n",
       "3           0     1         0            1  ...   \n",
       "4           0     0         1            0  ...   \n",
       "..        ...   ...       ...          ...  ...   \n",
       "702         0     0         0            0  ...   \n",
       "703         0     1         1            0  ...   \n",
       "704         0     1         1            1  ...   \n",
       "705         1     0         1            0  ...   \n",
       "706         1     0         0            0  ...   \n",
       "\n",
       "     toenail_loss_and_speech_problem  toenail_loss_or_speech_problem   \n",
       "0                                  0                               0  \\\n",
       "1                                  0                               0   \n",
       "2                                  1                               1   \n",
       "3                                  0                               0   \n",
       "4                                  0                               1   \n",
       "..                               ...                             ...   \n",
       "702                                0                               0   \n",
       "703                                0                               0   \n",
       "704                                0                               0   \n",
       "705                                0                               0   \n",
       "706                                0                               1   \n",
       "\n",
       "     toenail_loss_xor_speech_problem  toenail_loss_and_bullseye_rash   \n",
       "0                                  0                               0  \\\n",
       "1                                  0                               0   \n",
       "2                                  0                               1   \n",
       "3                                  0                               0   \n",
       "4                                  1                               0   \n",
       "..                               ...                             ...   \n",
       "702                                0                               0   \n",
       "703                                0                               0   \n",
       "704                                0                               0   \n",
       "705                                0                               0   \n",
       "706                                1                               0   \n",
       "\n",
       "     toenail_loss_or_bullseye_rash  toenail_loss_xor_bullseye_rash   \n",
       "0                                0                               0  \\\n",
       "1                                0                               0   \n",
       "2                                1                               0   \n",
       "3                                0                               0   \n",
       "4                                1                               1   \n",
       "..                             ...                             ...   \n",
       "702                              0                               0   \n",
       "703                              0                               0   \n",
       "704                              0                               0   \n",
       "705                              0                               0   \n",
       "706                              1                               1   \n",
       "\n",
       "     speech_problem_and_bullseye_rash  speech_problem_or_bullseye_rash   \n",
       "0                                   0                                0  \\\n",
       "1                                   0                                0   \n",
       "2                                   1                                1   \n",
       "3                                   0                                0   \n",
       "4                                   0                                0   \n",
       "..                                ...                              ...   \n",
       "702                                 0                                0   \n",
       "703                                 0                                0   \n",
       "704                                 0                                0   \n",
       "705                                 0                                0   \n",
       "706                                 0                                0   \n",
       "\n",
       "     speech_problem_xor_bullseye_rash  prognosis  \n",
       "0                                   0          3  \n",
       "1                                   0          7  \n",
       "2                                   0          3  \n",
       "3                                   0         10  \n",
       "4                                   0          6  \n",
       "..                                ...        ...  \n",
       "702                                 0          5  \n",
       "703                                 0          4  \n",
       "704                                 0         10  \n",
       "705                                 0          5  \n",
       "706                                 0          7  \n",
       "\n",
       "[707 rows x 6113 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.astype(int)\n",
    "\n",
    "col_prognosis = train_df[target_column]\n",
    "train_x = train_df.drop(columns=['prognosis'])\n",
    "train_x = combine_features(train_x)\n",
    "train_x['prognosis'] = col_prognosis\n",
    "train_df = train_x.copy()\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### `Clustering`\n",
    "\n",
    "To gather more information from the data, ***feature clustering*** was applied. This involved summing up the number of features that contained a specific keyword (for example `pain`) in their name and had a value of 1 in a specific sample. The sum was then added to a new column (say, `c_0`). \n",
    "\n",
    "This combines and counts the occurrences of pain-related symptoms in the dataset, and represent the overall presence or intensity of the symptom pain for each sample in the data. \n",
    "\n",
    "The clustering process allows to simplify and condense multiple individual features into a single aggregated cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_features(df):    \n",
    "    c_0 = df.columns[df.columns.str.contains('pain')]\n",
    "    c_1 = df.columns[df.columns.str.contains('inflammation')]\n",
    "    c_2 = df.columns[df.columns.str.contains('bleed')]\n",
    "    c_3 = df.columns[df.columns.str.contains('skin')]\n",
    "    df[\"c_0\"] = df[c_0].sum(axis=1)\n",
    "    df[\"c_1\"] = df[c_1].sum(axis=1)\n",
    "    df[\"c_2\"] = df[c_2].sum(axis=1)\n",
    "    df[\"c_3\"] = df[c_3].sum(axis=1) \n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>toenail_loss_or_bullseye_rash</th>\n",
       "      <th>toenail_loss_xor_bullseye_rash</th>\n",
       "      <th>speech_problem_and_bullseye_rash</th>\n",
       "      <th>speech_problem_or_bullseye_rash</th>\n",
       "      <th>speech_problem_xor_bullseye_rash</th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>707</td>\n",
       "      <td>168</td>\n",
       "      <td>356</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>36</td>\n",
       "      <td>157</td>\n",
       "      <td>137</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>822</td>\n",
       "      <td>375</td>\n",
       "      <td>496</td>\n",
       "      <td>252</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>235</td>\n",
       "      <td>425</td>\n",
       "      <td>252</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>147</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511</td>\n",
       "      <td>203</td>\n",
       "      <td>409</td>\n",
       "      <td>165</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>199</td>\n",
       "      <td>320</td>\n",
       "      <td>163</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>174</td>\n",
       "      <td>295</td>\n",
       "      <td>183</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>759</td>\n",
       "      <td>330</td>\n",
       "      <td>367</td>\n",
       "      <td>252</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>66</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 6117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain   \n",
       "0               1         1            0           1            1           1  \\\n",
       "1               0         0            0           0            0           0   \n",
       "2               0         1            1           1            0           1   \n",
       "3               0         0            1           1            1           1   \n",
       "4               0         0            0           0            0           0   \n",
       "..            ...       ...          ...         ...          ...         ...   \n",
       "702             0         0            1           1            1           0   \n",
       "703             1         0            1           1            1           1   \n",
       "704             1         0            1           0            1           0   \n",
       "705             1         1            0           0            1           0   \n",
       "706             1         1            0           0            0           0   \n",
       "\n",
       "     vomiting  rash  diarrhea  hypotension  ...   \n",
       "0           1     0         1            1  ...  \\\n",
       "1           1     0         1            0  ...   \n",
       "2           1     1         1            1  ...   \n",
       "3           0     1         0            1  ...   \n",
       "4           0     0         1            0  ...   \n",
       "..        ...   ...       ...          ...  ...   \n",
       "702         0     0         0            0  ...   \n",
       "703         0     1         1            0  ...   \n",
       "704         0     1         1            1  ...   \n",
       "705         1     0         1            0  ...   \n",
       "706         1     0         0            0  ...   \n",
       "\n",
       "     toenail_loss_or_bullseye_rash  toenail_loss_xor_bullseye_rash   \n",
       "0                                0                               0  \\\n",
       "1                                0                               0   \n",
       "2                                1                               0   \n",
       "3                                0                               0   \n",
       "4                                1                               1   \n",
       "..                             ...                             ...   \n",
       "702                              0                               0   \n",
       "703                              0                               0   \n",
       "704                              0                               0   \n",
       "705                              0                               0   \n",
       "706                              1                               1   \n",
       "\n",
       "     speech_problem_and_bullseye_rash  speech_problem_or_bullseye_rash   \n",
       "0                                   0                                0  \\\n",
       "1                                   0                                0   \n",
       "2                                   1                                1   \n",
       "3                                   0                                0   \n",
       "4                                   0                                0   \n",
       "..                                ...                              ...   \n",
       "702                                 0                                0   \n",
       "703                                 0                                0   \n",
       "704                                 0                                0   \n",
       "705                                 0                                0   \n",
       "706                                 0                                0   \n",
       "\n",
       "     speech_problem_xor_bullseye_rash  c_0  c_1  c_2  c_3  prognosis  \n",
       "0                                   0  707  168  356  112          3  \n",
       "1                                   0   84   36  157  137          7  \n",
       "2                                   0  822  375  496  252          3  \n",
       "3                                   0  640  235  425  252         10  \n",
       "4                                   0   84  147   48   24          6  \n",
       "..                                ...  ...  ...  ...  ...        ...  \n",
       "702                                 0  511  203  409  165          5  \n",
       "703                                 0  503  199  320  163          4  \n",
       "704                                 0  522  174  295  183         10  \n",
       "705                                 0  759  330  367  252          5  \n",
       "706                                 0  342   66   88   44          7  \n",
       "\n",
       "[707 rows x 6117 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_prognosis = train_df[target_column]\n",
    "train_x = train_df.drop(columns=['prognosis'])\n",
    "train_x = cluster_features(train_x)\n",
    "train_x['prognosis'] = col_prognosis\n",
    "train_df = train_x.copy()\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### `Affinity Propagation`\n",
    "\n",
    "Affinity Propagation is a clustering algorithm used in machine learning and data analysis. The algorithm is based on the concept of **message passing** among data points to determine which points should be considered as **exemplars, or representatives**, of clusters. The exemplars are chosen based on their **affinity** or similarity to other data points in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_propagation_features(df):\n",
    "    from sklearn.cluster import AffinityPropagation\n",
    "    from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "    X = manhattan_distances(df)\n",
    "    af = AffinityPropagation(random_state=0, affinity=\"precomputed\").fit(X)\n",
    "    cluster_centers_indices = af.cluster_centers_indices_\n",
    "    n_clusters_ = len(cluster_centers_indices)\n",
    "\n",
    "    df['cluster'] = af.labels_\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>toenail_loss_xor_bullseye_rash</th>\n",
       "      <th>speech_problem_and_bullseye_rash</th>\n",
       "      <th>speech_problem_or_bullseye_rash</th>\n",
       "      <th>speech_problem_xor_bullseye_rash</th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>cluster</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>707</td>\n",
       "      <td>168</td>\n",
       "      <td>356</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>36</td>\n",
       "      <td>157</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>822</td>\n",
       "      <td>375</td>\n",
       "      <td>496</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>235</td>\n",
       "      <td>425</td>\n",
       "      <td>252</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>147</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511</td>\n",
       "      <td>203</td>\n",
       "      <td>409</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>199</td>\n",
       "      <td>320</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>174</td>\n",
       "      <td>295</td>\n",
       "      <td>183</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>759</td>\n",
       "      <td>330</td>\n",
       "      <td>367</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>66</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 6118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain   \n",
       "0               1         1            0           1            1           1  \\\n",
       "1               0         0            0           0            0           0   \n",
       "2               0         1            1           1            0           1   \n",
       "3               0         0            1           1            1           1   \n",
       "4               0         0            0           0            0           0   \n",
       "..            ...       ...          ...         ...          ...         ...   \n",
       "702             0         0            1           1            1           0   \n",
       "703             1         0            1           1            1           1   \n",
       "704             1         0            1           0            1           0   \n",
       "705             1         1            0           0            1           0   \n",
       "706             1         1            0           0            0           0   \n",
       "\n",
       "     vomiting  rash  diarrhea  hypotension  ...   \n",
       "0           1     0         1            1  ...  \\\n",
       "1           1     0         1            0  ...   \n",
       "2           1     1         1            1  ...   \n",
       "3           0     1         0            1  ...   \n",
       "4           0     0         1            0  ...   \n",
       "..        ...   ...       ...          ...  ...   \n",
       "702         0     0         0            0  ...   \n",
       "703         0     1         1            0  ...   \n",
       "704         0     1         1            1  ...   \n",
       "705         1     0         1            0  ...   \n",
       "706         1     0         0            0  ...   \n",
       "\n",
       "     toenail_loss_xor_bullseye_rash  speech_problem_and_bullseye_rash   \n",
       "0                                 0                                 0  \\\n",
       "1                                 0                                 0   \n",
       "2                                 0                                 1   \n",
       "3                                 0                                 0   \n",
       "4                                 1                                 0   \n",
       "..                              ...                               ...   \n",
       "702                               0                                 0   \n",
       "703                               0                                 0   \n",
       "704                               0                                 0   \n",
       "705                               0                                 0   \n",
       "706                               1                                 0   \n",
       "\n",
       "     speech_problem_or_bullseye_rash  speech_problem_xor_bullseye_rash  c_0   \n",
       "0                                  0                                 0  707  \\\n",
       "1                                  0                                 0   84   \n",
       "2                                  1                                 0  822   \n",
       "3                                  0                                 0  640   \n",
       "4                                  0                                 0   84   \n",
       "..                               ...                               ...  ...   \n",
       "702                                0                                 0  511   \n",
       "703                                0                                 0  503   \n",
       "704                                0                                 0  522   \n",
       "705                                0                                 0  759   \n",
       "706                                0                                 0  342   \n",
       "\n",
       "     c_1  c_2  c_3  cluster  prognosis  \n",
       "0    168  356  112        0          3  \n",
       "1     36  157  137        1          7  \n",
       "2    375  496  252        0          3  \n",
       "3    235  425  252        2         10  \n",
       "4    147   48   24        1          6  \n",
       "..   ...  ...  ...      ...        ...  \n",
       "702  203  409  165        1          5  \n",
       "703  199  320  163        1          4  \n",
       "704  174  295  183        2         10  \n",
       "705  330  367  252        0          5  \n",
       "706   66   88   44        1          7  \n",
       "\n",
       "[707 rows x 6118 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_prognosis = train_df[target_column]\n",
    "train_x = train_df.drop(columns=['prognosis'])\n",
    "train_features = cluster_features(train_x)    \n",
    "train_df = affinity_propagation_features(train_features)\n",
    "train_df['prognosis'] = col_prognosis\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### `Feature Selection`\n",
    "\n",
    "Since the dataset from the previous step contains `6118` features, it was important to utilize a certain number of **most important features** to reduce the computational cost downstream. This was achieved using feature ranking with **recursive feature elimination (`RFE`)**.\n",
    "\n",
    "Using an external estimator (`RandomForestClassifier`), the least significant features are iteratively eliminated. It starts by training an estimator on the full feature set and ranks the features based on their importance. Then, it removes the least important feature(s) and repeats the process until a desired number of features (`n_features_to_select`) is reached. This mitigates over-fitting and improves generalization by focusing on the most informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sudden_fever_xor_mouth_bleed', 'sudden_fever_xor_muscle_pain',\n",
       "       'sudden_fever_xor_swelling', 'sudden_fever_xor_nausea',\n",
       "       'sudden_fever_xor_fatigue', 'sudden_fever_xor_weight_loss',\n",
       "       'sudden_fever_xor_anemia', 'headache_xor_rash',\n",
       "       'headache_xor_diarrhea', 'headache_xor_facial_distortion',\n",
       "       'mouth_bleed_xor_joint_pain', 'mouth_bleed_xor_hypotension',\n",
       "       'mouth_bleed_xor_pleural_effusion', 'mouth_bleed_xor_nausea',\n",
       "       'mouth_bleed_xor_chills', 'mouth_bleed_xor_fatigue',\n",
       "       'nose_bleed_xor_joint_pain', 'nose_bleed_xor_nausea',\n",
       "       'nose_bleed_xor_neck_pain', 'nose_bleed_xor_weakness',\n",
       "       'nose_bleed_xor_weight_loss', 'nose_bleed_xor_diziness',\n",
       "       'nose_bleed_xor_loss_of_appetite', 'nose_bleed_xor_hypoglycemia',\n",
       "       'muscle_pain_xor_diarrhea', 'muscle_pain_xor_nausea',\n",
       "       'muscle_pain_xor_chills', 'muscle_pain_xor_gum_bleed',\n",
       "       'joint_pain_xor_vomiting', 'joint_pain_xor_weight_loss',\n",
       "       'joint_pain_or_rigor', 'joint_pain_xor_toenail_loss',\n",
       "       'vomiting_or_rash', 'vomiting_xor_microcephaly',\n",
       "       'rash_xor_pleural_effusion', 'rash_xor_gastro_bleeding',\n",
       "       'diarrhea_xor_chills', 'diarrhea_xor_myalgia',\n",
       "       'diarrhea_xor_weight_loss', 'diarrhea_xor_lymph_swells',\n",
       "       'diarrhea_or_lips_irritation', 'hypotension_or_digestion_trouble',\n",
       "       'hypotension_or_diziness', 'hypotension_xor_red_eyes',\n",
       "       'pleural_effusion_or_back_pain', 'pleural_effusion_xor_back_pain',\n",
       "       'pleural_effusion_xor_diziness',\n",
       "       'pleural_effusion_or_hyperpyrexia',\n",
       "       'ascites_xor_digestion_trouble', 'ascites_xor_skin_lesions',\n",
       "       'ascites_or_weakness', 'ascites_or_coma', 'ascites_xor_anemia',\n",
       "       'ascites_xor_itchiness', 'nausea_xor_weakness',\n",
       "       'nausea_xor_back_pain', 'nausea_xor_coma',\n",
       "       'nausea_or_lymph_swells', 'myalgia_xor_digestion_trouble',\n",
       "       'myalgia_xor_gum_bleed', 'digestion_trouble_xor_itchiness',\n",
       "       'digestion_trouble_or_bullseye_rash', 'fatigue_xor_microcephaly',\n",
       "       'skin_lesions_or_yellow_eyes', 'stomach_pain_xor_coma',\n",
       "       'stomach_pain_or_itchiness', 'orbital_pain_or_itchiness',\n",
       "       'back_pain_or_tremor', 'back_pain_or_itchiness',\n",
       "       'weight_loss_xor_loss_of_appetite', 'weight_loss_or_irritability',\n",
       "       'weight_loss_or_paralysis', 'jaundice_or_abdominal_pain',\n",
       "       'jaundice_or_toenail_loss', 'coma_or_hyperpyrexia',\n",
       "       'coma_or_itchiness', 'coma_or_toenail_loss',\n",
       "       'diziness_or_yellow_skin', 'diziness_xor_toenail_loss',\n",
       "       'inflammation_or_irritability', 'red_eyes_xor_bitter_tongue',\n",
       "       'loss_of_appetite_or_hyperpyrexia', 'loss_of_appetite_xor_ulcers',\n",
       "       'urination_loss_or_cocacola_urine', 'urination_loss_xor_paralysis',\n",
       "       'urination_loss_or_toenail_loss',\n",
       "       'slow_heart_rate_xor_toenail_loss',\n",
       "       'light_sensitivity_or_yellow_skin', 'yellow_skin_or_irritability',\n",
       "       'yellow_eyes_or_prostraction', 'facial_distortion_or_toenail_loss',\n",
       "       'microcephaly_or_toenail_loss', 'convulsion_or_toenail_loss',\n",
       "       'anemia_or_itchiness', 'hyperpyrexia_or_itchiness', 'c_0', 'c_1',\n",
       "       'c_2', 'c_3', 'cluster'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "y = train_df[target_column]\n",
    "X = train_df.drop(columns = [target_column], axis = 1)\n",
    "\n",
    "rfe_selector = RFE(estimator = RandomForestClassifier(), n_features_to_select = 100, step = 20)\n",
    "rfe_selector.fit(X, y)\n",
    "\n",
    "rfe_selector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever_xor_mouth_bleed</th>\n",
       "      <th>sudden_fever_xor_muscle_pain</th>\n",
       "      <th>sudden_fever_xor_swelling</th>\n",
       "      <th>sudden_fever_xor_nausea</th>\n",
       "      <th>sudden_fever_xor_fatigue</th>\n",
       "      <th>sudden_fever_xor_weight_loss</th>\n",
       "      <th>sudden_fever_xor_anemia</th>\n",
       "      <th>headache_xor_rash</th>\n",
       "      <th>headache_xor_diarrhea</th>\n",
       "      <th>headache_xor_facial_distortion</th>\n",
       "      <th>...</th>\n",
       "      <th>microcephaly_or_toenail_loss</th>\n",
       "      <th>convulsion_or_toenail_loss</th>\n",
       "      <th>anemia_or_itchiness</th>\n",
       "      <th>hyperpyrexia_or_itchiness</th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>cluster</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>707</td>\n",
       "      <td>168</td>\n",
       "      <td>356</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>36</td>\n",
       "      <td>157</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>822</td>\n",
       "      <td>375</td>\n",
       "      <td>496</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>235</td>\n",
       "      <td>425</td>\n",
       "      <td>252</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>147</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511</td>\n",
       "      <td>203</td>\n",
       "      <td>409</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>199</td>\n",
       "      <td>320</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>174</td>\n",
       "      <td>295</td>\n",
       "      <td>183</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>759</td>\n",
       "      <td>330</td>\n",
       "      <td>367</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "      <td>66</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever_xor_mouth_bleed  sudden_fever_xor_muscle_pain   \n",
       "0                               1                             0  \\\n",
       "1                               0                             0   \n",
       "2                               1                             0   \n",
       "3                               1                             1   \n",
       "4                               0                             0   \n",
       "..                            ...                           ...   \n",
       "702                             1                             1   \n",
       "703                             0                             0   \n",
       "704                             0                             0   \n",
       "705                             1                             0   \n",
       "706                             1                             1   \n",
       "\n",
       "     sudden_fever_xor_swelling  sudden_fever_xor_nausea   \n",
       "0                            1                        0  \\\n",
       "1                            0                        1   \n",
       "2                            1                        1   \n",
       "3                            1                        1   \n",
       "4                            0                        0   \n",
       "..                         ...                      ...   \n",
       "702                          1                        0   \n",
       "703                          1                        0   \n",
       "704                          1                        0   \n",
       "705                          0                        0   \n",
       "706                          1                        1   \n",
       "\n",
       "     sudden_fever_xor_fatigue  sudden_fever_xor_weight_loss   \n",
       "0                           0                             0  \\\n",
       "1                           0                             0   \n",
       "2                           1                             1   \n",
       "3                           1                             0   \n",
       "4                           0                             0   \n",
       "..                        ...                           ...   \n",
       "702                         0                             0   \n",
       "703                         1                             1   \n",
       "704                         0                             0   \n",
       "705                         0                             0   \n",
       "706                         1                             1   \n",
       "\n",
       "     sudden_fever_xor_anemia  headache_xor_rash  headache_xor_diarrhea   \n",
       "0                          0                  1                      0  \\\n",
       "1                          0                  0                      1   \n",
       "2                          1                  0                      0   \n",
       "3                          1                  1                      0   \n",
       "4                          0                  0                      1   \n",
       "..                       ...                ...                    ...   \n",
       "702                        0                  0                      0   \n",
       "703                        1                  1                      1   \n",
       "704                        1                  1                      1   \n",
       "705                        1                  1                      0   \n",
       "706                        0                  1                      1   \n",
       "\n",
       "     headache_xor_facial_distortion  ...  microcephaly_or_toenail_loss   \n",
       "0                                 1  ...                             0  \\\n",
       "1                                 0  ...                             0   \n",
       "2                                 0  ...                             1   \n",
       "3                                 1  ...                             0   \n",
       "4                                 0  ...                             1   \n",
       "..                              ...  ...                           ...   \n",
       "702                               1  ...                             1   \n",
       "703                               1  ...                             1   \n",
       "704                               1  ...                             1   \n",
       "705                               1  ...                             1   \n",
       "706                               0  ...                             1   \n",
       "\n",
       "     convulsion_or_toenail_loss  anemia_or_itchiness   \n",
       "0                             0                    1  \\\n",
       "1                             0                    0   \n",
       "2                             1                    1   \n",
       "3                             0                    1   \n",
       "4                             1                    1   \n",
       "..                          ...                  ...   \n",
       "702                           0                    0   \n",
       "703                           0                    0   \n",
       "704                           0                    0   \n",
       "705                           1                    0   \n",
       "706                           1                    1   \n",
       "\n",
       "     hyperpyrexia_or_itchiness  c_0  c_1  c_2  c_3  cluster  prognosis  \n",
       "0                            0  707  168  356  112        0          3  \n",
       "1                            0   84   36  157  137        1          7  \n",
       "2                            1  822  375  496  252        0          3  \n",
       "3                            0  640  235  425  252        2         10  \n",
       "4                            1   84  147   48   24        1          6  \n",
       "..                         ...  ...  ...  ...  ...      ...        ...  \n",
       "702                          0  511  203  409  165        1          5  \n",
       "703                          0  503  199  320  163        1          4  \n",
       "704                          0  522  174  295  183        2         10  \n",
       "705                          0  759  330  367  252        0          5  \n",
       "706                          1  342   66   88   44        1          7  \n",
       "\n",
       "[707 rows x 101 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[rfe_selector.get_feature_names_out()]\n",
    "train_df['prognosis'] = y\n",
    "\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Dimensionality Reduction: `Principle Component Analysis`\n",
    "\n",
    "To further reduce the the load on computational resources and training times (*curse of dimensionilty*), **Dimensionality Reduction** can be utilized.\n",
    "\n",
    "**Principle Component Analysis (PCA)** is a linear dimensionality reduction technique, which takes advantage of existing correlations between the correlated features in the dataset, and combines them into a new set (`n_components`) of uncorrelated variables. PCA is an unsupervised algorithm as it does not require labels in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# X = train_df.drop(columns=[target_column], axis=1)\n",
    "\n",
    "# pca = PCA(n_components=30, random_state=42)\n",
    "# X_with_PCA = pca.fit_transform(X)\n",
    "\n",
    "# print(f'{X_with_PCA.shape}')\n",
    "\n",
    "# train_df = pd.DataFrame(X_with_PCA)\n",
    "# train_df['prognosis'] = y\n",
    "\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Dimensionality Reduction: `Linear Discriminant Analysis`\n",
    "\n",
    "Another method of dimensionality reduction using **Linear Discriminant Analysis (LDA)** involves reducing the number of features in a dataset while preserving the discriminative information between different classes. It works by calculating summary statistics for the input features by class label, and therefore is a method of supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707, 10)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.689151</td>\n",
       "      <td>1.176507</td>\n",
       "      <td>-1.856703</td>\n",
       "      <td>-2.382950</td>\n",
       "      <td>0.051157</td>\n",
       "      <td>0.371267</td>\n",
       "      <td>2.033049</td>\n",
       "      <td>-0.367083</td>\n",
       "      <td>-1.267465</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.821057</td>\n",
       "      <td>0.061279</td>\n",
       "      <td>-0.602860</td>\n",
       "      <td>0.941407</td>\n",
       "      <td>-0.673834</td>\n",
       "      <td>1.325486</td>\n",
       "      <td>0.549414</td>\n",
       "      <td>-1.072189</td>\n",
       "      <td>0.644849</td>\n",
       "      <td>2.085138</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.254471</td>\n",
       "      <td>0.321837</td>\n",
       "      <td>-4.589910</td>\n",
       "      <td>1.561719</td>\n",
       "      <td>0.523623</td>\n",
       "      <td>-0.719989</td>\n",
       "      <td>1.775101</td>\n",
       "      <td>1.194403</td>\n",
       "      <td>-0.207628</td>\n",
       "      <td>1.221859</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.960438</td>\n",
       "      <td>0.243622</td>\n",
       "      <td>-0.050933</td>\n",
       "      <td>1.841326</td>\n",
       "      <td>-1.785081</td>\n",
       "      <td>0.762675</td>\n",
       "      <td>-0.789212</td>\n",
       "      <td>1.063284</td>\n",
       "      <td>-0.762090</td>\n",
       "      <td>-0.890367</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.542549</td>\n",
       "      <td>-2.272394</td>\n",
       "      <td>-2.370382</td>\n",
       "      <td>-0.777403</td>\n",
       "      <td>-0.700121</td>\n",
       "      <td>0.062891</td>\n",
       "      <td>0.136774</td>\n",
       "      <td>-1.340705</td>\n",
       "      <td>-0.345849</td>\n",
       "      <td>-0.181144</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>1.279614</td>\n",
       "      <td>0.746589</td>\n",
       "      <td>1.715658</td>\n",
       "      <td>-0.303633</td>\n",
       "      <td>1.286105</td>\n",
       "      <td>-1.429838</td>\n",
       "      <td>-1.342462</td>\n",
       "      <td>0.608598</td>\n",
       "      <td>1.003644</td>\n",
       "      <td>1.838449</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>-0.511616</td>\n",
       "      <td>1.341881</td>\n",
       "      <td>0.640289</td>\n",
       "      <td>1.391345</td>\n",
       "      <td>-2.075107</td>\n",
       "      <td>-0.802148</td>\n",
       "      <td>-1.042681</td>\n",
       "      <td>0.887457</td>\n",
       "      <td>-0.227744</td>\n",
       "      <td>0.212705</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>2.454551</td>\n",
       "      <td>0.973558</td>\n",
       "      <td>1.124523</td>\n",
       "      <td>1.141421</td>\n",
       "      <td>0.345780</td>\n",
       "      <td>0.336307</td>\n",
       "      <td>2.110872</td>\n",
       "      <td>-0.243935</td>\n",
       "      <td>0.831485</td>\n",
       "      <td>1.063449</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1.570869</td>\n",
       "      <td>2.072863</td>\n",
       "      <td>-0.639099</td>\n",
       "      <td>0.252440</td>\n",
       "      <td>2.333390</td>\n",
       "      <td>-1.565427</td>\n",
       "      <td>0.674011</td>\n",
       "      <td>0.380539</td>\n",
       "      <td>0.217824</td>\n",
       "      <td>-1.325827</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>-1.402609</td>\n",
       "      <td>-3.568604</td>\n",
       "      <td>-0.861654</td>\n",
       "      <td>0.108419</td>\n",
       "      <td>0.379195</td>\n",
       "      <td>-2.181229</td>\n",
       "      <td>-1.338557</td>\n",
       "      <td>0.103888</td>\n",
       "      <td>0.538025</td>\n",
       "      <td>0.601530</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \n",
       "0    0.689151  1.176507 -1.856703 -2.382950  0.051157  0.371267  2.033049  \\\n",
       "1   -2.821057  0.061279 -0.602860  0.941407 -0.673834  1.325486  0.549414   \n",
       "2    2.254471  0.321837 -4.589910  1.561719  0.523623 -0.719989  1.775101   \n",
       "3    1.960438  0.243622 -0.050933  1.841326 -1.785081  0.762675 -0.789212   \n",
       "4   -0.542549 -2.272394 -2.370382 -0.777403 -0.700121  0.062891  0.136774   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "702  1.279614  0.746589  1.715658 -0.303633  1.286105 -1.429838 -1.342462   \n",
       "703 -0.511616  1.341881  0.640289  1.391345 -2.075107 -0.802148 -1.042681   \n",
       "704  2.454551  0.973558  1.124523  1.141421  0.345780  0.336307  2.110872   \n",
       "705  1.570869  2.072863 -0.639099  0.252440  2.333390 -1.565427  0.674011   \n",
       "706 -1.402609 -3.568604 -0.861654  0.108419  0.379195 -2.181229 -1.338557   \n",
       "\n",
       "            7         8         9  prognosis  \n",
       "0   -0.367083 -1.267465  0.002335          3  \n",
       "1   -1.072189  0.644849  2.085138          7  \n",
       "2    1.194403 -0.207628  1.221859          3  \n",
       "3    1.063284 -0.762090 -0.890367         10  \n",
       "4   -1.340705 -0.345849 -0.181144          6  \n",
       "..        ...       ...       ...        ...  \n",
       "702  0.608598  1.003644  1.838449          5  \n",
       "703  0.887457 -0.227744  0.212705          4  \n",
       "704 -0.243935  0.831485  1.063449         10  \n",
       "705  0.380539  0.217824 -1.325827          5  \n",
       "706  0.103888  0.538025  0.601530          7  \n",
       "\n",
       "[707 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "y = train_df[target_column]\n",
    "X = train_df.drop(columns=[target_column], axis=1)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_with_LDA = lda.fit_transform(X, y)\n",
    "joblib.dump(lda, 'lda_model.pkl')\n",
    "\n",
    "print(f'{X_with_LDA.shape}\\n')\n",
    "\n",
    "train_df = pd.DataFrame(X_with_LDA)\n",
    "\n",
    "train_df['prognosis'] = y\n",
    "\n",
    "train_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## 3. Splitting the Holdout Train and Test Data for Hyperparameter Tuning\n",
    "<br>\n",
    "\n",
    "![Division of Data](./images/data_division.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707, 11)\n",
      "(530, 11)\n",
      "(177, 11)\n"
     ]
    }
   ],
   "source": [
    "n_samples = train_df.shape[0]\n",
    "n_features = train_df.shape[1] - 1\n",
    "train_df.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df.drop(target_column, axis=1), train_df[target_column],\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.25,\n",
    "                                                    stratify=train_df[target_column])\n",
    "trainset = pd.DataFrame(np.hstack((X_train, np.array(y_train).reshape(-1, 1))))\n",
    "testset = pd.DataFrame(np.hstack((X_test, np.array(y_test).reshape(-1, 1))))\n",
    "trainset.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "testset.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
    "print(train_df.shape)\n",
    "print(trainset.shape)\n",
    "print(testset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## 3. `fun_control`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inializing `fun_control` dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = fun_control_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Adding information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the dataset to the fun_control\n",
    "fun_control.update({\"data\": train_df, # full dataset,\n",
    "               \"train\": trainset,\n",
    "               \"test\": testset,\n",
    "               \"n_samples\": n_samples,\n",
    "               \"target_column\": target_column})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_model = None\n",
    "fun_control.update({\"prep_model\": prep_model})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Selecting the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control = add_core_model_to_fun_control(core_model=RandomForestClassifier,\n",
    "                              fun_control=fun_control,\n",
    "                              hyper_dict=SklearnHyperDict,\n",
    "                              filename=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Listing the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators\n",
      "criterion\n",
      "max_depth\n",
      "min_samples_split\n",
      "min_samples_leaf\n",
      "min_weight_fraction_leaf\n",
      "max_features\n",
      "max_leaf_nodes\n",
      "min_impurity_decrease\n",
      "bootstrap\n",
      "oob_score\n"
     ]
    }
   ],
   "source": [
    "print(*fun_control[\"core_model_hyper_dict\"].keys(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Selecting and modifying hyperparameter bounds for tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Criterion**: method that calculates information gain (also called impurity) in the trees \n",
    "\n",
    "* **n_estimators**: number of trees \n",
    "\n",
    "* **max_depth**: the maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. \n",
    "\n",
    "* **min_samples_split**: minimum number of data points a node needs before splitting further. \n",
    "\n",
    "* **min_samples_leaf**: a split point will only be considered if in both the left and right node there are at least min_samples_leaf amount of data points present. \n",
    "\n",
    "* **max_features**: determines how the number of features for the random feature selection is calculated  \n",
    "\n",
    "* **max_leaf_nodes**: defines how many leaf nodes a tree can have \n",
    "\n",
    "* **min_impurity_decrease**: minimum value for impurity decrease, amount of information gain, a node split should provide. \n",
    "\n",
    "* **bootstrap**: whether or not bootstrapping is used. \n",
    "\n",
    "* **oob_score**: whether or not out of bag samples are used to estimate generalisation performance. Out of bag samples are samples not used in bagging. This score takes advantage of bagging to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"n_estimators\", bounds=[5, 9])\n",
    "# fun_control[\"core_model_hyper_dict\"][\"n_estimators\"]\n",
    "\n",
    "# # fun_control = modify_hyper_parameter_bounds(fun_control, \"criterion\", [\"gini\", \"entropy\", \"log_loss\"])\n",
    "# # fun_control[\"core_model_hyper_dict\"][\"criterion\"]\n",
    "\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"max_depth\", bounds=[1, 20])\n",
    "# fun_control[\"core_model_hyper_dict\"][\"max_depth\"]\n",
    "\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"min_samples_split\", bounds=[2, 100])\n",
    "# fun_control[\"core_model_hyper_dict\"][\"min_samples_split\"]\n",
    "\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"min_samples_leaf\", bounds=[1, 10])\n",
    "# fun_control[\"core_model_hyper_dict\"][\"min_samples_leaf\"]\n",
    "\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"min_weight_fraction_leaf\", bounds=[0.0, 0.01])\n",
    "# fun_control[\"core_model_hyper_dict\"][\"min_weight_fraction_leaf\"]\n",
    "\n",
    "# # fun_control = modify_hyper_parameter_bounds(fun_control, \"max_features\", [\"sqrt\", \"log2\", \"none\"])\n",
    "# # fun_control[\"core_model_hyper_dict\"][\"max_features\"]\n",
    "\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"max_leaf_nodes\", bounds=[7, 12])\n",
    "# fun_control[\"core_model_hyper_dict\"][\"max_leaf_nodes\"]\n",
    "\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"min_impurity_decrease\", bounds=[0.0, 0.01])\n",
    "# fun_control[\"core_model_hyper_dict\"][\"min_impurity_decrease\"]\n",
    "\n",
    "# fun_control = modify_hyper_parameter_bounds(fun_control, \"bootstrap\", [0, 1])\n",
    "# fun_control[\"core_model_hyper_dict\"][\"bootstrap\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Setting `map@k` as the `loss_function` metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `map@k` or **Mean Average Precision at K** an error metric that can be used when the sequence of your predictions plays an important role in the objective of the task. In our objective, since it is desired to know whether the correctly predicted prognosis is within the top `k =3` predictions, `map@k` is a suitable metric to use for oprimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control.update({\n",
    "               \"weights\": -1,\n",
    "               \"metric_sklearn\": mapk_score,\n",
    "               \"predict_proba\": True,\n",
    "               \"metric_params\": {\"k\": 3},\n",
    "               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Using `oob_score` to evaluate model performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the OOB-Score is a very efficient way to estimate the performance of a random forest classifier. If the OOB-Score is used, the key \"eval\" in the `fun_control` dictionary should be set to `\"oob_score\"` as shown below. In addition to setting the key `\"eval\"` in the `fun_control` dictionary to `\"oob_score\"`, the keys `\"oob_score\"` and `\"bootstrap\"` have to be set to `True`, because the OOB-Score requires the bootstrap method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_control.update({\n",
    "    \"eval\": \"eval_oob_score\",\n",
    "})\n",
    "fun_control = modify_hyper_parameter_bounds(fun_control, \"bootstrap\", bounds=[1, 1])\n",
    "fun_control = modify_hyper_parameter_bounds(fun_control, \"oob_score\", bounds=[1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## 4. Preparing and Running `spot_tuner`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting bounds for `spot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type = get_var_type(fun_control)\n",
    "var_name = get_var_name(fun_control)\n",
    "fun_control.update({\"var_type\": var_type,\n",
    "                    \"var_name\": var_name})\n",
    "\n",
    "lower = get_bound_values(fun_control, \"lower\")\n",
    "upper = get_bound_values(fun_control, \"upper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name                     | type   | default   |   lower |   upper | transform              |\n",
      "|--------------------------|--------|-----------|---------|---------|------------------------|\n",
      "| n_estimators             | int    | 7         |       5 |   10    | transform_power_2_int  |\n",
      "| criterion                | factor | gini      |       0 |    2    | None                   |\n",
      "| max_depth                | int    | 10        |       1 |   20    | transform_power_2_int  |\n",
      "| min_samples_split        | int    | 2         |       2 |  100    | None                   |\n",
      "| min_samples_leaf         | int    | 1         |       1 |   25    | None                   |\n",
      "| min_weight_fraction_leaf | float  | 0.0       |       0 |    0.01 | None                   |\n",
      "| max_features             | factor | sqrt      |       0 |    1    | transform_none_to_None |\n",
      "| max_leaf_nodes           | int    | 10        |       7 |   12    | transform_power_2_int  |\n",
      "| min_impurity_decrease    | float  | 0.0       |       0 |    0.01 | None                   |\n",
      "| bootstrap                | factor | 1         |       1 |    1    | None                   |\n",
      "| oob_score                | factor | 0         |       1 |    1    | None                   |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Hyperparamter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_dict=SklearnHyperDict().load()\n",
    "X_start = get_default_hyperparameters_as_array(fun_control, hyper_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = HyperSklearn(seed=123, log_level=50).fun_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: [##########] 100.00% Done...\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spotPython.spot.spot.Spot at 0x1d5d1d35090>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spot_tuner = spot.Spot(fun=fun,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   fun_repeats = 1,\n",
    "                   max_time = MAX_TIME,\n",
    "                   noise = False,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type = var_type,\n",
    "                   var_name = var_name,\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=123,\n",
    "                   log_level = 50,\n",
    "                   show_models= False,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": INIT_SIZE,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": True,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": len(var_name),\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 10_000,\n",
    "                                      \"log_level\": 50\n",
    "                                      })\n",
    "spot_tuner.run(X_start=X_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Analyzing the tuning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Progress Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_tuner.plot_progress(log_y=False, filename=\"../Figures.d/\" + experiment_name+\"_progress.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "* Getting the tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name                     | type   | default   |   lower |   upper |                 tuned | transform              |   importance | stars   |\n",
      "|--------------------------|--------|-----------|---------|---------|-----------------------|------------------------|--------------|---------|\n",
      "| n_estimators             | int    | 7         |     5.0 |    10.0 |                   9.0 | transform_power_2_int  |        16.55 | *       |\n",
      "| criterion                | factor | gini      |     0.0 |     2.0 |                   0.0 | None                   |         0.84 | .       |\n",
      "| max_depth                | int    | 10        |     1.0 |    20.0 |                   8.0 | transform_power_2_int  |       100.00 | ***     |\n",
      "| min_samples_split        | int    | 2         |     2.0 |   100.0 |                   4.0 | None                   |         9.01 | *       |\n",
      "| min_samples_leaf         | int    | 1         |     1.0 |    25.0 |                   4.0 | None                   |         7.21 | *       |\n",
      "| min_weight_fraction_leaf | float  | 0.0       |     0.0 |    0.01 |                  0.01 | None                   |         0.00 |         |\n",
      "| max_features             | factor | sqrt      |     0.0 |     1.0 |                   1.0 | transform_none_to_None |        46.57 | *       |\n",
      "| max_leaf_nodes           | int    | 10        |     7.0 |    12.0 |                  11.0 | transform_power_2_int  |         0.71 | .       |\n",
      "| min_impurity_decrease    | float  | 0.0       |     0.0 |    0.01 | 0.0015748368906723118 | None                   |         6.53 | *       |\n",
      "| bootstrap                | factor | 1         |     1.0 |     1.0 |                   1.0 | None                   |         0.00 |         |\n",
      "| oob_score                | factor | 0         |     1.0 |     1.0 |                   1.0 | None                   |         0.00 |         |\n"
     ]
    }
   ],
   "source": [
    "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "* Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_tuner.plot_importance(threshold=1.0, filename=\"../Figures.d/\" + experiment_name+\"_importance.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## 5. Evaluation and Comparison with `default` model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting default model with default parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 128,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 1024,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': 1024,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'bootstrap': 1,\n",
       " 'oob_score': 0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_default = get_default_values(fun_control)\n",
    "values_default = transform_hyper_parameter_values(fun_control=fun_control, hyper_parameter_values=values_default)\n",
    "values_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;nonetype&#x27;, None),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(bootstrap=1, max_depth=1024,\n",
       "                                        max_leaf_nodes=1024, n_estimators=128,\n",
       "                                        oob_score=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;nonetype&#x27;, None),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(bootstrap=1, max_depth=1024,\n",
       "                                        max_leaf_nodes=1024, n_estimators=128,\n",
       "                                        oob_score=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">None</label><div class=\"sk-toggleable__content\"><pre>None</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=1, max_depth=1024, max_leaf_nodes=1024,\n",
       "                       n_estimators=128, oob_score=0)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('nonetype', None),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(bootstrap=1, max_depth=1024,\n",
       "                                        max_leaf_nodes=1024, n_estimators=128,\n",
       "                                        oob_score=0))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_default = make_pipeline(fun_control[\"prep_model\"], fun_control[\"core_model\"](**values_default))\n",
    "model_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Getting tuned parameters and model from `spot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_estimators': 512,\n",
       "  'criterion': 'gini',\n",
       "  'max_depth': 256,\n",
       "  'min_samples_split': 4,\n",
       "  'min_samples_leaf': 4,\n",
       "  'min_weight_fraction_leaf': 0.01,\n",
       "  'max_features': 'log2',\n",
       "  'max_leaf_nodes': 2048,\n",
       "  'min_impurity_decrease': 0.0015748368906723118,\n",
       "  'bootstrap': 1,\n",
       "  'oob_score': 1}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\n",
    "v_dict = assign_values(X, fun_control[\"var_name\"])\n",
    "return_conf_list_from_var_dict(var_dict=v_dict, fun_control=fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=1, max_depth=256, max_features=&#x27;log2&#x27;,\n",
       "                       max_leaf_nodes=2048,\n",
       "                       min_impurity_decrease=0.0015748368906723118,\n",
       "                       min_samples_leaf=4, min_samples_split=4,\n",
       "                       min_weight_fraction_leaf=0.01, n_estimators=512,\n",
       "                       oob_score=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=1, max_depth=256, max_features=&#x27;log2&#x27;,\n",
       "                       max_leaf_nodes=2048,\n",
       "                       min_impurity_decrease=0.0015748368906723118,\n",
       "                       min_samples_leaf=4, min_samples_split=4,\n",
       "                       min_weight_fraction_leaf=0.01, n_estimators=512,\n",
       "                       oob_score=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(bootstrap=1, max_depth=256, max_features='log2',\n",
       "                       max_leaf_nodes=2048,\n",
       "                       min_impurity_decrease=0.0015748368906723118,\n",
       "                       min_samples_leaf=4, min_samples_split=4,\n",
       "                       min_weight_fraction_leaf=0.01, n_estimators=512,\n",
       "                       oob_score=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spot = get_one_sklearn_model_from_X(X, fun_control)\n",
    "model_spot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Fetching `train` and `test` data from `fun_control`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((177, 10), (177,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = get_Xy_from_df(fun_control[\"train\"], fun_control[\"target_column\"])\n",
    "X_test, y_test = get_Xy_from_df(fun_control[\"test\"], fun_control[\"target_column\"])\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### One-time `map@k` scores \n",
    "\n",
    "The `map@k` scores for **default** and the **tuned** models are calculated only once and compared. However, this is not a definitive metric of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `model_spot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6007532956685498"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spot.fit(X_train, y_train)\n",
    "y_pred = model_spot.predict_proba(X_test)\n",
    "res = mapk_score(y_true=y_test, y_pred=y_pred, k=3)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `model_default`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5847457627118644"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_default.fit(X_train, y_train)[\"randomforestclassifier\"]\n",
    "y_pred = model_default.predict_proba(X_test)\n",
    "mapk_score(y_true=y_test, y_pred=y_pred, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "#### Repeated evaluation on hold-out data \n",
    "\n",
    "The `map@k` scores are then calculated `n = 30` times for both the models in order to analyze the min, max and mean scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_eval(n, model):\n",
    "    res_values = []\n",
    "    for i in range(n):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        res = mapk_score(y_true=y_test, y_pred=y_pred, k=3)\n",
    "        res_values.append(res)\n",
    "    mean_res = np.mean(res_values)\n",
    "    print(f\"mean_res: {mean_res}\")\n",
    "    std_res = np.std(res_values)\n",
    "    print(f\"std_res: {std_res}\")\n",
    "    min_res = np.min(res_values)\n",
    "    print(f\"min_res: {min_res}\")\n",
    "    max_res = np.max(res_values)\n",
    "    print(f\"max_res: {max_res}\")\n",
    "    median_res = np.median(res_values)\n",
    "    print(f\"median_res: {median_res}\")\n",
    "    return mean_res, std_res, min_res, max_res, median_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `model_spot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_res: 0.6058694287507848\n",
      "std_res: 0.004890885694773723\n",
      "min_res: 0.5932203389830508\n",
      "max_res: 0.615819209039548\n",
      "median_res: 0.6059322033898304\n"
     ]
    }
   ],
   "source": [
    "_ = repeated_eval(30, model_spot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `model_default`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_res: 0.5942561205273069\n",
      "std_res: 0.006822032273702421\n",
      "min_res: 0.5819209039548022\n",
      "max_res: 0.6054613935969868\n",
      "median_res: 0.5922787193973635\n"
     ]
    }
   ],
   "source": [
    "_ = repeated_eval(10, model_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## 6. Cross-validated Evaluations\n",
    "\n",
    "The **k-fold Cross Validated** results are a better representative of model performance since the generalized scores over multiple train and test evaluations are considered. \n",
    "\n",
    "The evaulations are perfomed for both the model for `trainset`, `testset`, and the whole `train.csv` data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `trainset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.589622641509434, None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotPython.sklearn.traintest import evaluate_cv\n",
    "\n",
    "fun_control.update({\n",
    "     \"eval\": \"train_cv\",\n",
    "     \"k_folds\": 10,\n",
    "})\n",
    "evaluate_cv(model=model_spot, fun_control=fun_control, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `testset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.57260348583878, None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_control.update({\n",
    "     \"eval\": \"test_cv\",\n",
    "     \"k_folds\": 10,\n",
    "})\n",
    "evaluate_cv(model=model_spot, fun_control=fun_control, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6011535881958416, None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_control.update({\n",
    "     \"eval\": \"data_cv\",\n",
    "     \"k_folds\": 10,\n",
    "})\n",
    "evaluate_cv(model=model_spot, fun_control=fun_control, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## 7. Generating Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv('./data/Kaggle/test.csv')\n",
    "# col_id = test_df['id']\n",
    "\n",
    "# test_df = test_df.astype(int)\n",
    "# test_df = combine_features(test_df)\n",
    "# test_df = cluster_features(test_df)\n",
    "# test_df = affinity_propagation_features(test_df)\n",
    "# test_df = test_df[rfe_selector.get_feature_names_out()]\n",
    "\n",
    "# lda1 = joblib.load('lda_model.pkl')\n",
    "# test_df = pd.DataFrame(lda1.transform(test_df))\n",
    "\n",
    "# n_features = test_df.shape[1] - 1\n",
    "# test_df.columns = [f\"x{i}\" for i in range(1, n_features+2)]\n",
    "\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = model_spot.predict_proba(test_df)\n",
    "\n",
    "# test_sorted_prediction_ids = np.argsort(-y, axis=1)\n",
    "# test_top_3_prediction_ids = test_sorted_prediction_ids[:,:3]\n",
    "# original_shape = test_top_3_prediction_ids.shape\n",
    "# test_top_3_prediction = enc.inverse_transform(test_top_3_prediction_ids.reshape(-1, 1))\n",
    "# test_top_3_prediction = test_top_3_prediction.reshape(original_shape)\n",
    "\n",
    "# test_df['prognosis'] = np.apply_along_axis(lambda x: np.array(' '.join(x), dtype=\"object\"), 1, test_top_3_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame()\n",
    "\n",
    "# submission['id'] = col_id\n",
    "# submission['prognosis'] = test_df['prognosis']\n",
    "\n",
    "# submission.to_csv('./data/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotCondaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
